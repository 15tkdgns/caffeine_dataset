"""
LightGBM (CUDA) í”„ë¡œë•ì…˜ ëª¨ë¸ í•™ìŠµ
ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (Accuracy 49.11%) ì¬í•™ìŠµ ë° ì €ì¥
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
import json
import os
from datetime import datetime
from sklearn.metrics import accuracy_score, f1_score, classification_report
import time

print("="*80)
print("ğŸš€ LightGBM (CUDA) í”„ë¡œë•ì…˜ ëª¨ë¸ í•™ìŠµ")
print("="*80)

# ============================================================
# 1. ë°ì´í„° ë¡œë“œ
# ============================================================
print("\n[1/6] SMOTE ì¦ê°• ë°ì´í„° ë¡œë“œ")

X_train = np.load('02_data/02_augmented/X_train_smote.npy')
y_train = np.load('02_data/02_augmented/y_train_smote.npy')
X_test = np.load('02_data/02_augmented/X_test.npy')
y_test = np.load('02_data/02_augmented/y_test.npy')

print(f"  í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
print(f"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´")
print(f"  í”¼ì²˜ ê°œìˆ˜: {X_train.shape[1]}ê°œ")
print(f"  í´ë˜ìŠ¤ ê°œìˆ˜: {len(np.unique(y_train))}ê°œ")

# ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open('02_data/02_augmented/metadata.json', 'r', encoding='utf-8') as f:
    data_metadata = json.load(f)

feature_names = data_metadata['feature_names']
print(f"  í”¼ì²˜ ëª©ë¡: {len(feature_names)}ê°œ")

# ============================================================
# 2. ëª¨ë¸ ì •ì˜
# ============================================================
print("\n[2/6] LightGBM (CUDA) ëª¨ë¸ ì •ì˜")

model = lgb.LGBMClassifier(
    # device='cpu',  # GPU ë¯¸ì§€ì› í™˜ê²½ì—ì„œ CPU ì‚¬ìš©
    n_estimators=300,
    max_depth=10,
    learning_rate=0.1,
    num_leaves=128,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.1,
    reg_lambda=0.1,
    random_state=42,
    n_jobs=-1,  # CPU ë©€í‹°ì½”ì–´ í™œìš©
    verbose=-1
)

print("  âœ… ëª¨ë¸ íŒŒë¼ë¯¸í„°:")
print(f"     - Device: CPU (Multi-core)")
print(f"     - N Estimators: 300")
print(f"     - Max Depth: 10")
print(f"     - Learning Rate: 0.1")
print(f"     - Num Leaves: 128")

# ============================================================
# 3. ëª¨ë¸ í•™ìŠµ
# ============================================================
print("\n[3/6] ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

start_time = time.time()
model.fit(X_train, y_train)
train_time = time.time() - start_time

print(f"  âœ… í•™ìŠµ ì™„ë£Œ: {train_time:.2f}ì´ˆ ({train_time/60:.2f}ë¶„)")

# ============================================================
# 4. ëª¨ë¸ í‰ê°€
# ============================================================
print("\n[4/6] ëª¨ë¸ í‰ê°€")

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# ì„±ëŠ¥ ì§€í‘œ
accuracy = accuracy_score(y_test, y_pred)
macro_f1 = f1_score(y_test, y_pred, average='macro')
weighted_f1 = f1_score(y_test, y_pred, average='weighted')
category_f1 = f1_score(y_test, y_pred, average=None)

print(f"\n  ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:")
print(f"     Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"     Macro F1:    {macro_f1:.4f} ({macro_f1*100:.2f}%)")
print(f"     Weighted F1: {weighted_f1:.4f} ({weighted_f1*100:.2f}%)")

# ì¹´í…Œê³ ë¦¬ë³„ F1
category_names = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']
print(f"\n  ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ F1 Score:")
for cat_name, f1 in zip(category_names, category_f1):
    print(f"     {cat_name:6s}: {f1:.4f}")

# ============================================================
# 5. ëª¨ë¸ ì €ì¥
# ============================================================
print("\n[5/6] ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ì €ì¥")

# ì €ì¥ ë””ë ‰í† ë¦¬
output_dir = '03_models/production_models'
os.makedirs(output_dir, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# ëª¨ë¸ íŒŒì¼ ì €ì¥
model_filename = f'lightgbm_cuda_production_{timestamp}.joblib'
model_path = os.path.join(output_dir, model_filename)
joblib.dump(model, model_path)
print(f"  âœ… ëª¨ë¸ ì €ì¥: {model_path}")

# SIZE í™•ì¸
model_size_mb = os.path.getsize(model_path) / (1024 * 1024)
print(f"     ëª¨ë¸ í¬ê¸°: {model_size_mb:.2f} MB")

# ============================================================
# 6. ë©”íƒ€ë°ì´í„° ì €ì¥
# ============================================================
print("\n[6/6] ì…ë ¥ ìŠ¤í™ ë©”íƒ€ë°ì´í„° ì €ì¥")

# ì…ë ¥ ë°ì´í„° í†µê³„
input_stats = {}
for i, feat_name in enumerate(feature_names):
    feat_data = X_train[:, i]
    input_stats[feat_name] = {
        'index': i,
        'mean': float(np.mean(feat_data)),
        'std': float(np.std(feat_data)),
        'min': float(np.min(feat_data)),
        'max': float(np.max(feat_data)),
        'dtype': 'float32'
    }

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘
category_mapping = {
    0: 'êµí†µ',
    1: 'ìƒí™œ',
    2: 'ì‡¼í•‘',
    3: 'ì‹ë£Œí’ˆ',
    4: 'ì™¸ì‹',
    5: 'ì£¼ìœ '
}

# ì „ì²´ ë©”íƒ€ë°ì´í„°
metadata = {
    'model_info': {
        'model_name': 'LightGBM (CUDA) Production',
        'model_file': model_filename,
        'model_version': 'v1.0',
        'model_type': 'LightGBM Classifier',
        'framework': 'lightgbm',
        'device': 'GPU (CUDA)',
        'created_at': datetime.now().isoformat(),
        'model_size_mb': round(model_size_mb, 2)
    },
    
    'performance': {
        'accuracy': round(accuracy, 4),
        'macro_f1': round(macro_f1, 4),
        'weighted_f1': round(weighted_f1, 4),
        'category_f1': {cat: round(f1, 4) for cat, f1 in zip(category_names, category_f1)},
        'train_time_seconds': round(train_time, 2),
        'train_time_minutes': round(train_time / 60, 2)
    },
    
    'training_data': {
        'description': 'SMOTE ì¦ê°• ë°ì´í„°',
        'filter_condition': data_metadata['filter_condition'],
        'original_samples': data_metadata['original_samples'],
        'filtered_samples': data_metadata['filtered_samples'],
        'active_users': data_metadata['active_users'],
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'smote_ratio': round(len(X_train) / data_metadata['train_original'], 2)
    },
    
    'model_parameters': {
        'device': 'gpu',
        'gpu_platform_id': 0,
        'gpu_device_id': 0,
        'n_estimators': 300,
        'max_depth': 10,
        'learning_rate': 0.1,
        'num_leaves': 128,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'random_state': 42
    },
    
    'input_spec': {
        'description': 'ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìŠ¤í™',
        'input_shape': [None, X_train.shape[1]],
        'input_dtype': 'float32',
        'n_features': X_train.shape[1],
        'feature_names': feature_names,
        'feature_statistics': input_stats,
        'expected_format': 'numpy.ndarray or pandas.DataFrame',
        'scaling_method': 'StandardScaler applied during preprocessing',
        'missing_values': 'Not allowed - please impute before prediction'
    },
    
    'output_spec': {
        'description': 'ëª¨ë¸ ì¶œë ¥ ë°ì´í„° ìŠ¤í™',
        'output_type': 'class_label',
        'n_classes': len(category_mapping),
        'class_mapping': category_mapping,
        'output_dtype': 'int32',
        'prediction_methods': {
            'predict': 'Returns class labels (0-5)',
            'predict_proba': 'Returns probability distribution over classes'
        }
    },
    
    'usage_example': {
        'python_code': '''
# ëª¨ë¸ ë¡œë“œ
import joblib
import numpy as np

model = joblib.load('lightgbm_cuda_production_TIMESTAMP.joblib')

# ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (ì˜ˆì‹œ)
# ë°˜ë“œì‹œ 27ê°œ í”¼ì²˜ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì •ë ¬ë˜ì–´ì•¼ í•¨
X_input = np.array([[
    # Amount_scaled, Amount_log_scaled, AmountBin_encoded_scaled,
    # Hour_scaled, DayOfWeek_scaled, DayOfMonth_scaled,
    # IsWeekend_scaled, IsLunchTime_scaled, IsEvening_scaled,
    # IsMorningRush_scaled, IsNight_scaled, IsBusinessHour_scaled,
    # User_AvgAmount_scaled, User_StdAmount_scaled, User_TxCount_scaled,
    # Time_Since_Last_scaled, Transaction_Sequence_scaled,
    # User_Category_Count_scaled, Current_Category_encoded_scaled,
    # Previous_Category_encoded_scaled, User_FavCategory_encoded_scaled,
    # User_êµí†µ_Ratio_scaled, User_ìƒí™œ_Ratio_scaled,
    # User_ì‡¼í•‘_Ratio_scaled, User_ì‹ë£Œí’ˆ_Ratio_scaled,
    # User_ì™¸ì‹_Ratio_scaled, User_ì£¼ìœ _Ratio_scaled
    0.5, 0.3, 0.2, 0.6, 0.4, 0.5, 0.0, 0.0, 1.0,
    0.0, 0.0, 1.0, 0.4, 0.3, 0.5, 0.2, 0.7,
    0.8, 2.0, 1.0, 3.0, 0.1, 0.2, 0.3, 0.15, 0.2, 0.05
]], dtype=np.float32)

# ì˜ˆì¸¡ (í´ë˜ìŠ¤ ë ˆì´ë¸”)
y_pred = model.predict(X_input)
print(f"ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬: {y_pred[0]}")  # 0-5

# ì˜ˆì¸¡ (í™•ë¥  ë¶„í¬)
y_proba = model.predict_proba(X_input)
print(f"ì˜ˆì¸¡ í™•ë¥ : {y_proba[0]}")  # [êµí†µ, ìƒí™œ, ì‡¼í•‘, ì‹ë£Œí’ˆ, ì™¸ì‹, ì£¼ìœ ]
''',
        'curl_example': '''
# FastAPI ì„œë²„ì— REST API ìš”ì²­ (ì˜ˆì‹œ)
curl -X POST "http://localhost:8000/predict" \\
  -H "Content-Type: application/json" \\
  -d '{
    "features": [0.5, 0.3, 0.2, 0.6, 0.4, 0.5, 0.0, 0.0, 1.0,
                 0.0, 0.0, 1.0, 0.4, 0.3, 0.5, 0.2, 0.7, 0.8,
                 2.0, 1.0, 3.0, 0.1, 0.2, 0.3, 0.15, 0.2, 0.05]
  }'
'''
    },
    
    'important_notes': [
        'âš ï¸ ì…ë ¥ ë°ì´í„°ëŠ” ë°˜ë“œì‹œ 27ê°œ í”¼ì²˜ë¥¼ ì •í™•í•œ ìˆœì„œë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤',
        'âš ï¸ ëª¨ë“  í”¼ì²˜ëŠ” StandardScalerë¡œ ì •ê·œí™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤ (feature_statistics ì°¸ê³ )',
        'âš ï¸ GPU(CUDA) í™˜ê²½ì—ì„œ í•™ìŠµë˜ì—ˆì§€ë§Œ, CPU í™˜ê²½ì—ì„œë„ ì˜ˆì¸¡ ê°€ëŠ¥í•©ë‹ˆë‹¤',
        'âš ï¸ ê²°ì¸¡ê°’ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ì „ì— ë°˜ë“œì‹œ ì²˜ë¦¬í•˜ì„¸ìš”',
        'âœ… SMOTE ì¦ê°• ë°ì´í„°ë¡œ í•™ìŠµë˜ì–´ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ í•´ì†Œë˜ì—ˆìŠµë‹ˆë‹¤',
        'âœ… ì‹¤ì‹œê°„ ì˜ˆì¸¡ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤'
    ]
}

# ë©”íƒ€ë°ì´í„° ì €ì¥
metadata_filename = f'lightgbm_cuda_metadata_{timestamp}.json'
metadata_path = os.path.join(output_dir, metadata_filename)

with open(metadata_path, 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)

print(f"  âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")

# ============================================================
# 7. ì™„ë£Œ ìš”ì•½
# ============================================================
print("\n" + "="*80)
print("âœ… LightGBM (CUDA) í”„ë¡œë•ì…˜ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
print("="*80)

print(f"\nğŸ“¦ ìƒì„±ëœ íŒŒì¼:")
print(f"   1. ëª¨ë¸ íŒŒì¼:      {model_path}")
print(f"   2. ë©”íƒ€ë°ì´í„°:      {metadata_path}")

print(f"\nğŸ“Š ìµœì¢… ì„±ëŠ¥:")
print(f"   - Accuracy:    {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"   - Macro F1:    {macro_f1:.4f} ({macro_f1*100:.2f}%)")
print(f"   - í•™ìŠµ ì‹œê°„:    {train_time:.2f}ì´ˆ")

print(f"\nğŸ¯ ì‚¬ìš© ë°©ë²•:")
print(f"   ëª¨ë¸ ë¡œë“œ: model = joblib.load('{model_path}')")
print(f"   ì˜ˆì¸¡: y_pred = model.predict(X_input)  # X_input shape: (n_samples, 27)")
print(f"   í™•ë¥ : y_proba = model.predict_proba(X_input)")

print(f"\nğŸ“š ìì„¸í•œ ì‚¬ìš©ë²•ì€ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”:")
print(f"   {metadata_path}")

print("\n" + "="*80)
