#!/usr/bin/env python3
"""
ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ìƒì„±ì¼: 2025-12-10
"""

import joblib
import json
import os
import sys

def verify_model():
    """ëª¨ë¸ íŒŒì¼ ê²€ì¦ ë° ì •ë³´ ì¶œë ¥"""
    
    model_path = "best_model_xgboost_acc_73.47.joblib"
    metadata_path = "best_model_metadata.json"
    
    print("=" * 70)
    print("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê²€ì¦")
    print("=" * 70)
    
    # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        sys.exit(1)
    
    if not os.path.exists(metadata_path):
        print(f"âš ï¸  ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_path}")
    
    # 2. íŒŒì¼ í¬ê¸° í™•ì¸
    model_size_mb = os.path.getsize(model_path) / (1024 * 1024)
    print(f"\nğŸ“¦ ëª¨ë¸ íŒŒì¼ ì •ë³´:")
    print(f"   - ê²½ë¡œ: {os.path.abspath(model_path)}")
    print(f"   - í¬ê¸°: {model_size_mb:.2f} MB")
    
    # 3. ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    try:
        print(f"\nğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        model = joblib.load(model_path)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print(f"   - íƒ€ì…: {type(model).__name__}")
        
        # ëª¨ë¸ ì†ì„± í™•ì¸
        if hasattr(model, 'n_features_in_'):
            print(f"   - ì…ë ¥ í”¼ì²˜ ê°œìˆ˜: {model.n_features_in_}")
        if hasattr(model, 'n_classes_'):
            print(f"   - ì¶œë ¥ í´ë˜ìŠ¤ ê°œìˆ˜: {model.n_classes_}")
        if hasattr(model, 'classes_'):
            print(f"   - í´ë˜ìŠ¤ ë ˆì´ë¸”: {model.classes_}")
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    # 4. ë©”íƒ€ë°ì´í„° ì¶œë ¥
    if os.path.exists(metadata_path):
        print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ:")
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        best_model_name = metadata.get('best_model', 'Unknown')
        best_model_info = metadata.get('models', {}).get(best_model_name, {})
        
        print(f"   - ìµœê³  ëª¨ë¸: {best_model_name}")
        print(f"   - ì •í™•ë„: {best_model_info.get('accuracy', 0) * 100:.2f}%")
        print(f"   - Macro F1: {best_model_info.get('macro_f1', 0) * 100:.2f}%")
        print(f"   - Weighted F1: {best_model_info.get('weighted_f1', 0) * 100:.2f}%")
        print(f"   - í•™ìŠµ ì‹œê°„: {best_model_info.get('train_time', 0):.2f}ì´ˆ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ F1 Score
        category_f1 = best_model_info.get('category_f1', [])
        if category_f1:
            categories = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']
            print(f"\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ F1 Score:")
            for i, (cat, f1) in enumerate(zip(categories, category_f1)):
                medal = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else "  "
                print(f"   {medal} {cat}: {f1 * 100:.2f}%")
        
        # í”¼ì²˜ ì •ë³´
        features = metadata.get('features', [])
        print(f"\nğŸ”§ í”¼ì²˜ ì •ë³´:")
        print(f"   - ì´ {len(features)}ê°œ í”¼ì²˜")
        print(f"   - í”¼ì²˜ ëª©ë¡: {', '.join(features[:5])}...")
    
    # 5. ì‚¬ìš© ì˜ˆì‹œ
    print(f"\nğŸ’» ì‚¬ìš© ì˜ˆì‹œ:")
    print(f"""
    import joblib
    import numpy as np
    
    # ëª¨ë¸ ë¡œë“œ
    model = joblib.load('{model_path}')
    
    # ì˜ˆì¸¡ (24ê°œ í”¼ì²˜ í•„ìš”)
    X_sample = np.random.randn(1, {model.n_features_in_ if hasattr(model, 'n_features_in_') else 24})
    prediction = model.predict(X_sample)
    probability = model.predict_proba(X_sample)
    
    print(f"ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬: {{prediction[0]}}")
    print(f"ì˜ˆì¸¡ í™•ë¥ : {{probability[0]}}")
    """)
    
    print("=" * 70)
    print("âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!")
    print("=" * 70)

if __name__ == "__main__":
    verify_model()
