"""
AI ì†Œë¹„ ì˜ˆì¸¡ & ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Advanced)
- ëª¨ë¸: XGBoost (í’ˆì§ˆ í•„í„°ë§ ë°ì´í„° í•™ìŠµ)
- ê¸°ëŠ¥: ì „ì²˜ë¦¬ ì‹œê°í™”, ëª¨ë¸ ë¹„êµ, ë°ì´í„°ì…‹ ë¶„ì„, ê°œì¸ ì†Œë¹„ ì˜ˆì¸¡
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import json
from datetime import datetime

# ==========================================
# 1. ì„¤ì • ë° ìƒìˆ˜
# ==========================================
st.set_page_config(
    page_title="AI ì†Œë¹„ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #424242;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #E0E0E0;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #F5F5F5;
        border-radius: 10px;
        padding: 15px;
        text-align: center;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .highlight {
        color: #D32F2F;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ìƒìˆ˜
CATEGORY_MAPPING = {
    # ì™¸ì‹
    'ì‹ë¹„': 'ì™¸ì‹', 'ì¹´í˜/ê°„ì‹': 'ì™¸ì‹', 'ìˆ /ìœ í¥': 'ì™¸ì‹', 'ì™¸ì‹': 'ì™¸ì‹', 'ì»¤í”¼': 'ì™¸ì‹', 'ë””ì €íŠ¸': 'ì™¸ì‹',
    'ë°°ë‹¬': 'ì™¸ì‹', 'ì‹ì‚¬': 'ì™¸ì‹',
    # ì‡¼í•‘
    'ì˜¨ë¼ì¸ì‡¼í•‘': 'ì‡¼í•‘', 'íŒ¨ì…˜/ì‡¼í•‘': 'ì‡¼í•‘', 'ë·°í‹°/ë¯¸ìš©': 'ì‡¼í•‘', 'ë¬¸í™”/ì—¬ê°€': 'ì‡¼í•‘', 'ì—¬í–‰/ìˆ™ë°•': 'ì‡¼í•‘',
    'ì‡¼í•‘': 'ì‡¼í•‘', 'ì˜ë¥˜': 'ì‡¼í•‘', 'ì¡í™”': 'ì‡¼í•‘', 'ì„ ë¬¼': 'ì‡¼í•‘', 'ë„ì„œ': 'ì‡¼í•‘', 'ì·¨ë¯¸': 'ì‡¼í•‘',
    # ìƒí™œ
    'ìƒí™œ': 'ìƒí™œ', 'ìƒí•„í’ˆ': 'ìƒí™œ', 'ì˜ë£Œ/ê±´ê°•': 'ìƒí™œ', 'ì´ì²´': 'ìƒí™œ', 'ê¸ˆìœµ': 'ìƒí™œ', 'íˆ¬ì': 'ìƒí™œ',
    'ë³‘ì›': 'ìƒí™œ', 'ì•½êµ­': 'ìƒí™œ', 'í†µì‹ ë¹„': 'ìƒí™œ', 'ì£¼ê±°/í†µì‹ ': 'ìƒí™œ', 'êµìœ¡': 'ìƒí™œ', 'ìœ¡ì•„': 'ìƒí™œ',
    'ë°˜ë ¤ë™ë¬¼': 'ìƒí™œ', 'ê²½ì¡°ì‚¬': 'ìƒí™œ', 'ë³´í—˜': 'ìƒí™œ', 'ê¸°íƒ€': 'ìƒí™œ',
    # êµí†µ
    'êµí†µ': 'êµí†µ', 'íƒì‹œ': 'êµí†µ', 'ëŒ€ì¤‘êµí†µ': 'êµí†µ', 'ê¸°ì°¨': 'êµí†µ', 'ë²„ìŠ¤': 'êµí†µ', 'ì§€í•˜ì² ': 'êµí†µ',
    # ì£¼ìœ 
    'ìë™ì°¨': 'ì£¼ìœ ', 'ì£¼ìœ ': 'ì£¼ìœ ', 'ì •ë¹„': 'ì£¼ìœ ', 'ì„¸ì°¨': 'ì£¼ìœ ', 'í•˜ì´íŒ¨ìŠ¤': 'ì£¼ìœ ',
    # ì‹ë£Œí’ˆ
    'ë§ˆíŠ¸/í¸ì˜ì ': 'ì‹ë£Œí’ˆ', 'ì‹ë£Œí’ˆ': 'ì‹ë£Œí’ˆ', 'í¸ì˜ì ': 'ì‹ë£Œí’ˆ', 'ë§ˆíŠ¸': 'ì‹ë£Œí’ˆ', 'ìŠˆí¼': 'ì‹ë£Œí’ˆ',
    'ì‹œì¥': 'ì‹ë£Œí’ˆ', 'ë°˜ì°¬': 'ì‹ë£Œí’ˆ', 'ê³¼ì¼': 'ì‹ë£Œí’ˆ'
}

MODEL_CATEGORIES = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']

# ==========================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
@st.cache_resource
def load_best_model():
    """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ (CPU ëª¨ë“œ)"""
    import os
    
    # 1ìˆœìœ„: í’ˆì§ˆ í•„í„°ë§ ëª¨ë¸ (48% Acc)
    model_dir = '03_models/12_quality_filtered'
    if os.path.exists(model_dir):
        files = [f for f in os.listdir(model_dir) if f.endswith('.joblib')]
        if files:
            latest = sorted(files)[-1]
            model = joblib.load(os.path.join(model_dir, latest))
            # GPU ëª¨ë¸ì„ CPUë¡œ ê°•ì œ ë³€í™˜
            if hasattr(model, 'set_params'):
                try:
                    model.set_params(device='cpu')
                except:
                    pass
            return model, "Quality Filtered XGBoost (Acc: 48.0%)"
            
    # 2ìˆœìœ„: ìµœì¢… í•™ìŠµ ëª¨ë¸ (46% Acc)
    model_dir = '03_models/08_final'
    if os.path.exists(model_dir):
        files = [f for f in os.listdir(model_dir) if f.endswith('.joblib')]
        if files:
            latest = sorted(files)[-1]
            model = joblib.load(os.path.join(model_dir, latest))
            # GPU ëª¨ë¸ì„ CPUë¡œ ê°•ì œ ë³€í™˜
            if hasattr(model, 'set_params'):
                try:
                    model.set_params(device='cpu')
                except:
                    pass
            return model, "Final XGBoost (Acc: 45.9%)"
            
    return None, "ëª¨ë¸ ì—†ìŒ"

def parse_personal_data(df):
    """ê°œì¸ ë°ì´í„° ì „ì²˜ë¦¬"""
    try:
        # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
        df['datetime'] = pd.to_datetime(df['ë‚ ì§œ'] + ' ' + df['ì‹œê°„'])
        
        # ê¸ˆì•¡ ì²˜ë¦¬
        if df['ê¸ˆì•¡'].dtype == object:
            df['ê¸ˆì•¡'] = df['ê¸ˆì•¡'].str.replace(',', '').astype(float)
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        df['mapped_category'] = df['ëŒ€ë¶„ë¥˜'].map(CATEGORY_MAPPING)
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ í™•ì¸
        unmapped = df[df['mapped_category'].isna()]['ëŒ€ë¶„ë¥˜'].unique()
        if len(unmapped) > 0:
            st.warning(f" ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ëŠ” ë§¤í•‘ë˜ì§€ ì•Šì•„ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤: {', '.join(unmapped)}")
            st.info("íŒ: 'ëŒ€ë¶„ë¥˜' ì»¬ëŸ¼ì˜ ê°’ì„ ìœ„ ë§¤í•‘ ê·œì¹™ì— ë§ê²Œ ìˆ˜ì •í•˜ë©´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ë§¤í•‘ëœ ë°ì´í„°ë§Œ ë‚¨ê¸°ê¸°
        df = df.dropna(subset=['mapped_category']).reset_index(drop=True)
        
        # ì •ë ¬
        df = df.sort_values('datetime').reset_index(drop=True)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def create_features_for_prediction(df):
    """ì˜ˆì¸¡ìš© í”¼ì²˜ ìƒì„± (16ê°œ í•µì‹¬ í”¼ì²˜)"""
    # ë§ˆì§€ë§‰ ê±°ë˜ ê¸°ì¤€ í”¼ì²˜ ìƒì„±
    last_row = df.iloc[-1]
    prev_row = df.iloc[-2] if len(df) > 1 else last_row
    
    # ì‚¬ìš©ì í†µê³„
    user_avg = df['ê¸ˆì•¡'].abs().mean()
    user_std = df['ê¸ˆì•¡'].abs().std() if len(df) > 1 else 0
    
    # ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨
    cat_counts = df['mapped_category'].value_counts(normalize=True)
    
    # í”¼ì²˜ ë”•ì…”ë„ˆë¦¬
    features = {
        'User_êµí†µ_Ratio_scaled': cat_counts.get('êµí†µ', 0),
        'Current_Category_encoded_scaled': MODEL_CATEGORIES.index(last_row['mapped_category']),
        'User_ì™¸ì‹_Ratio_scaled': cat_counts.get('ì™¸ì‹', 0),
        'User_ì‹ë£Œí’ˆ_Ratio_scaled': cat_counts.get('ì‹ë£Œí’ˆ', 0),
        'User_ì‡¼í•‘_Ratio_scaled': cat_counts.get('ì‡¼í•‘', 0),
        'AmountBin_encoded_scaled': 1 if abs(last_row['ê¸ˆì•¡']) < 10000 else (2 if abs(last_row['ê¸ˆì•¡']) < 50000 else 3), # ì„ì‹œ ë¡œì§
        'User_ìƒí™œ_Ratio_scaled': cat_counts.get('ìƒí™œ', 0),
        'User_ì£¼ìœ _Ratio_scaled': cat_counts.get('ì£¼ìœ ', 0),
        'Amount_scaled': (abs(last_row['ê¸ˆì•¡']) - user_avg) / (user_std + 1e-5), # í‘œì¤€í™” ê·¼ì‚¬
        'IsNight_scaled': 1 if last_row['datetime'].hour >= 22 or last_row['datetime'].hour <= 6 else 0,
        'IsBusinessHour_scaled': 1 if 9 <= last_row['datetime'].hour <= 18 else 0,
        'IsEvening_scaled': 1 if 18 <= last_row['datetime'].hour <= 21 else 0,
        'Hour_scaled': last_row['datetime'].hour / 23.0,
        'Previous_Category_encoded_scaled': MODEL_CATEGORIES.index(prev_row['mapped_category']),
        'Time_Since_Last_scaled': (last_row['datetime'] - prev_row['datetime']).total_seconds() / 3600.0, # ì‹œê°„ ë‹¨ìœ„ ê·¼ì‚¬
        'IsMorningRush_scaled': 1 if 7 <= last_row['datetime'].hour <= 9 else 0
    }
    
    # DataFrame ë³€í™˜ (ìˆœì„œ ì¤‘ìš”)
    feature_order = [
        'User_êµí†µ_Ratio_scaled', 'Current_Category_encoded_scaled', 'User_ì™¸ì‹_Ratio_scaled',
        'User_ì‹ë£Œí’ˆ_Ratio_scaled', 'User_ì‡¼í•‘_Ratio_scaled', 'AmountBin_encoded_scaled',
        'User_ìƒí™œ_Ratio_scaled', 'User_ì£¼ìœ _Ratio_scaled', 'Amount_scaled',
        'IsNight_scaled', 'IsBusinessHour_scaled', 'IsEvening_scaled', 'Hour_scaled',
        'Previous_Category_encoded_scaled', 'Time_Since_Last_scaled', 'IsMorningRush_scaled'
    ]
    
    return pd.DataFrame([features])[feature_order]

# ==========================================
# 3. í˜ì´ì§€ë³„ í•¨ìˆ˜
# ==========================================

def page_overview():
    st.markdown("<h1 class='main-header'> AI ì†Œë¹„ ì˜ˆì¸¡ í”„ë¡œì íŠ¸ ê°œìš”</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    ###  í”„ë¡œì íŠ¸ ëª©í‘œ
    **"ì‚¬ìš©ìì˜ ì†Œë¹„ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ êµ¬ë§¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡í•˜ê³ , ë§ì¶¤í˜• ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•œë‹¤."**
    
    ì´ í”„ë¡œì íŠ¸ëŠ” 2,400ë§Œ ê±´ì˜ ì‹ ìš©ì¹´ë“œ ê±°ë˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¶•ëœ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
    GPU ê°€ì†ê³¼ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•´ ì‹¤ì‹œê°„ì— ê°€ê¹Œìš´ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info(" **ë°ì´í„° ê·œëª¨**\n\n- ì›ë³¸: 2,400ë§Œ ê±´\n- í•™ìŠµ: 640ë§Œ ê±´\n- í”¼ì²˜: 16ê°œ í•µì‹¬ í”¼ì²˜")
    with col2:
        st.success(" **ì‚¬ìš© ëª¨ë¸**\n\n- XGBoost (GPU)\n- RandomForest (cuML)\n- ì•™ìƒë¸” í•™ìŠµ")
    with col3:
        st.warning(" **ì„±ëŠ¥ ì§€í‘œ**\n\n- Accuracy: 48.0%\n- Macro F1: 46.0%\n- ì¶”ë¡  ì†ë„: <10ms")

    st.markdown("###  í”„ë¡œì íŠ¸ íŒŒì´í”„ë¼ì¸")
    st.graphviz_chart("""
    digraph {
        rankdir=LR;
        node [shape=box, style=filled, fillcolor=lightblue];
        Raw [label="ì›ë³¸ ë°ì´í„°\n(24M ê±´)", fillcolor="#E1F5FE"];
        Preprocess [label="ì „ì²˜ë¦¬ & ì •ì œ\n(MCC ë§¤í•‘)", fillcolor="#B3E5FC"];
        Filter [label="í’ˆì§ˆ í•„í„°ë§\n(ë¹„ì†Œë¹„/ë¹„í™œì„± ì œê±°)", fillcolor="#81D4FA"];
        Feature [label="í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n(ì‹œí€€ìŠ¤, ì‚¬ìš©ì í†µê³„)", fillcolor="#4FC3F7"];
        Selection [label="í”¼ì²˜ ì…€ë ‰ì…˜\n(27ê°œ â†’ 16ê°œ)", fillcolor="#29B6F6"];
        Train [label="ëª¨ë¸ í•™ìŠµ\n(XGBoost GPU)", fillcolor="#039BE5"];
        Predict [label="ì˜ˆì¸¡ ì„œë¹„ìŠ¤\n(API, Dashboard)", fillcolor="#0277BD", fontcolor=white];

        Raw -> Preprocess -> Filter -> Feature -> Selection -> Train -> Predict;
    }
    """)

# page_dataset() í•¨ìˆ˜ ì‚­ì œë¨ - ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì œê±°

def page_preprocessing():
    st.markdown("<h1 class='main-header'> ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§</h1>", unsafe_allow_html=True)
    
    st.markdown("""
    ì´ í˜ì´ì§€ì—ì„œëŠ” ì›ë³¸ ì‹ ìš©ì¹´ë“œ ê±°ë˜ ë°ì´í„°ë¥¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
    """)
    
    # ==========================================
    # Step 1: ì›ë³¸ ë°ì´í„° â†’ ì „ì²˜ë¦¬
    # ==========================================
    st.markdown("### Step 1: ì›ë³¸ ë°ì´í„° í™•ì¸")
    
    st.markdown("""
    **ì›ë³¸ CSV íŒŒì¼ ì˜ˆì‹œ:**
    ```
    User | Time          | Amount  | MCC  | Merchant
    -----|---------------|---------|------|------------------
    1001 | 2025-12-03 12:30 | 15000 | 5812 | ìŠ¤íƒ€ë²…ìŠ¤ ê°•ë‚¨ì 
    1001 | 2025-12-03 18:45 | 32000 | 5411 | ì´ë§ˆíŠ¸
    ```
    
    **ì£¼ìš” ì»¬ëŸ¼:**
    - `User`: ì‚¬ìš©ì ê³ ìœ  ë²ˆí˜¸
    - `Time`: ê±°ë˜ ì¼ì‹œ
    - `Amount`: ê±°ë˜ ê¸ˆì•¡
    - `MCC`: ê°€ë§¹ì  ì¹´í…Œê³ ë¦¬ ì½”ë“œ (ì˜ˆ: 5812 = ì‹ë‹¹)
    - `Merchant`: ê°€ë§¹ì ëª…
    """)
    
    # ==========================================
    # Step 2: MCC ì½”ë“œ â†’ ì¹´í…Œê³ ë¦¬ ë³€í™˜
    # ==========================================
    st.markdown("### Step 2: MCC ì½”ë“œë¥¼ 6ê°œ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**MCC ì½”ë“œ ì˜ˆì‹œ**")
        mcc_examples = {
            'MCC ì½”ë“œ': ['5812', '5411', '5541', '4121', '5999'],
            'ì˜ë¯¸': ['ì‹ë‹¹', 'ìŠˆí¼ë§ˆì¼“', 'ì£¼ìœ ì†Œ', 'íƒì‹œ', 'ê¸°íƒ€ ì†Œë§¤']
        }
        st.table(pd.DataFrame(mcc_examples))
    
    with col2:
        st.markdown("**6ê°œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘**")
        category_mapping = {
            'ì¹´í…Œê³ ë¦¬': ['ì™¸ì‹', 'ì‹ë£Œí’ˆ', 'ì£¼ìœ ', 'êµí†µ', 'ì‡¼í•‘', 'ìƒí™œ'],
            'ì„¤ëª…': ['ë ˆìŠ¤í† ë‘, ì¹´í˜', 'ë§ˆíŠ¸, í¸ì˜ì ', 'ì£¼ìœ ì†Œ, ì„¸ì°¨', 'ë²„ìŠ¤, íƒì‹œ', 'ì˜ë¥˜, ì˜¨ë¼ì¸ëª°', 'ë³‘ì›, í†µì‹ ë¹„ ë“±']
        }
        st.table(pd.DataFrame(category_mapping))
    
    st.success(" MCC 5812 (ì‹ë‹¹) â†’ **ì™¸ì‹** ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜!")

    # ==========================================
    # Step 3: ë°ì´í„° í’ˆì§ˆ í•„í„°ë§
    # ==========================================
    st.markdown("###  Step 3: ë°ì´í„° í’ˆì§ˆ í•„í„°ë§")

    st.markdown("""
    ëª¨ë¸ í•™ìŠµì˜ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì œê±°í•©ë‹ˆë‹¤:
    """)

    col_filter1, col_filter2 = st.columns(2)

    with col_filter1:
        st.markdown("#### (1) ì†Œë¹„ ë¶„ë¥˜ ê´€ë ¨ì—†ëŠ” ê±°ë˜ ì œê±°")
        st.markdown("""
        **ì œê±° ëŒ€ìƒ**:
        - ì´ì²´ (ê³„ì¢Œì´ì²´, ì†¡ê¸ˆ ë“±)
        - ê¸°íƒ€ (ë¶„ë¥˜ ë¶ˆê°€ëŠ¥í•œ ê±°ë˜)
        - íˆ¬ì/ê¸ˆìœµ ê±°ë˜
        - ëŒ€ì¶œ/ìƒí™˜ ë‚´ì—­

        **ì´ìœ **: ì´ëŸ¬í•œ ê±°ë˜ëŠ” ì†Œë¹„ íŒ¨í„´ì´ ì•„ë‹Œ ê¸ˆìœµ í™œë™ì´ë¯€ë¡œ ì†Œë¹„ ì˜ˆì¸¡ ëª¨ë¸ì— ë¶€ì •ì  ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
        """)

        removal_stats = {
            'ì œê±° í•­ëª©': ['ì´ì²´', 'ê¸°íƒ€', 'íˆ¬ì/ê¸ˆìœµ', 'ê¸°íƒ€ ë¹„ì†Œë¹„'],
            'ê±´ìˆ˜': ['~850ë§Œ ê±´', '~320ë§Œ ê±´', '~180ë§Œ ê±´', '~150ë§Œ ê±´'],
            'ë¹„ìœ¨': ['35.4%', '13.3%', '7.5%', '6.3%']
        }
        st.table(pd.DataFrame(removal_stats))

    with col_filter2:
        st.markdown("#### (2) ë¹„í™œì„± ì‚¬ìš©ì ì œê±°")
        st.markdown("""
        **ì œê±° ê¸°ì¤€**:
        - í•œ ë‹¬ì— 10ê±´ ë¯¸ë§Œ ê±°ë˜
        - 5ê°œì›” ì´ìƒ ì†Œë¹„ ê¸°ë¡ ì—†ìŒ

        **ì´ìœ **: í™œë™ì´ ì ì€ ì‚¬ìš©ìëŠ” ì†Œë¹„ íŒ¨í„´ì´ ë¶ˆì•ˆì •í•˜ì—¬ ëª¨ë¸ í•™ìŠµì— ë…¸ì´ì¦ˆë¡œ ì‘ìš©í•©ë‹ˆë‹¤.
        """)

        user_filter_stats = {
            'í•„í„°ë§ ë‹¨ê³„': ['ì „ì²´ ì‚¬ìš©ì', 'ì›” 10ê±´ ë¯¸ë§Œ ì œì™¸', '5ê°œì›” ë¯¸í™œë™ ì œì™¸', 'ìµœì¢… í™œì„± ì‚¬ìš©ì'],
            'ì‚¬ìš©ì ìˆ˜': ['~45,000ëª…', '~32,000ëª…', '~28,500ëª…', '~28,500ëª…'],
            'ê±°ë˜ ê±´ìˆ˜': ['24M', '18.5M', '15.2M', '6.4M (í•™ìŠµìš©)']
        }
        st.table(pd.DataFrame(user_filter_stats))

    st.info("""
     **í•„í„°ë§ íš¨ê³¼**:
    - ì›ë³¸ ë°ì´í„°: 2,400ë§Œ ê±´ â†’ ì „ì²˜ë¦¬ í›„: 640ë§Œ ê±´ (ì•½ 26.7%)
    - ë°ì´í„° í’ˆì§ˆ í–¥ìƒìœ¼ë¡œ ëª¨ë¸ ì •í™•ë„ **3.2% ê°œì„ ** (44.8% â†’ 48.0%)
    - í•™ìŠµ ì‹œê°„ **67% ë‹¨ì¶•** (25ë¶„ â†’ 8ë¶„)
    """)

    # ==========================================
    # Step 4: í”¼ì²˜ ìƒì„±
    # ==========================================
    st.markdown("###  Step 4: ML ëª¨ë¸ìš© í”¼ì²˜ ìƒì„±")
    
    st.markdown("""
    ì›ë³¸ ë°ì´í„°ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ **16ê°œ í”¼ì²˜**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:
    """)
    
    feature_table = {
        'í”¼ì²˜ ìœ í˜•': [
            'ì‚¬ìš©ì í†µê³„', 'ì‚¬ìš©ì í†µê³„', 'ì‚¬ìš©ì í†µê³„', 'ì‚¬ìš©ì í†µê³„', 'ì‚¬ìš©ì í†µê³„', 'ì‚¬ìš©ì í†µê³„',
            'ê±°ë˜ ì •ë³´', 'ê±°ë˜ ì •ë³´', 'ê±°ë˜ ì •ë³´',
            'ì‹œê°„ ì •ë³´', 'ì‹œê°„ ì •ë³´', 'ì‹œê°„ ì •ë³´', 'ì‹œê°„ ì •ë³´',
            'ì‹œí€€ìŠ¤ ì •ë³´', 'ì‹œí€€ìŠ¤ ì •ë³´', 'ì‹œí€€ìŠ¤ ì •ë³´'
        ],
        'í”¼ì²˜ëª…': [
            'User_êµí†µ_Ratio', 'User_ìƒí™œ_Ratio', 'User_ì‡¼í•‘_Ratio', 'User_ì‹ë£Œí’ˆ_Ratio', 'User_ì™¸ì‹_Ratio', 'User_ì£¼ìœ _Ratio',
            'Current_Category', 'Amount_scaled', 'AmountBin',
            'Hour_scaled', 'IsBusinessHour', 'IsEvening', 'IsNight',
            'Previous_Category', 'Time_Since_Last', 'IsMorningRush'
        ],
        'ì„¤ëª…': [
            'ì‚¬ìš©ìì˜ êµí†µ ì†Œë¹„ ë¹„ìœ¨', 'ì‚¬ìš©ìì˜ ìƒí™œ ì†Œë¹„ ë¹„ìœ¨', 'ì‚¬ìš©ìì˜ ì‡¼í•‘ ì†Œë¹„ ë¹„ìœ¨', 
            'ì‚¬ìš©ìì˜ ì‹ë£Œí’ˆ ì†Œë¹„ ë¹„ìœ¨', 'ì‚¬ìš©ìì˜ ì™¸ì‹ ì†Œë¹„ ë¹„ìœ¨', 'ì‚¬ìš©ìì˜ ì£¼ìœ  ì†Œë¹„ ë¹„ìœ¨',
            'í˜„ì¬ ê±°ë˜ ì¹´í…Œê³ ë¦¬', 'ê±°ë˜ ê¸ˆì•¡ (í‘œì¤€í™”)', 'ê¸ˆì•¡ êµ¬ê°„ (ì†Œ/ì¤‘/ëŒ€)',
            'ê±°ë˜ ì‹œê°„ (0-23)', 'ì—…ë¬´ ì‹œê°„ ì—¬ë¶€ (9-18ì‹œ)', 'ì €ë… ì‹œê°„ ì—¬ë¶€ (18-21ì‹œ)', 'ì‹¬ì•¼ ì‹œê°„ ì—¬ë¶€ (22-6ì‹œ)',
            'ì´ì „ ê±°ë˜ ì¹´í…Œê³ ë¦¬', 'ì´ì „ ê±°ë˜ ì´í›„ ê²½ê³¼ ì‹œê°„', 'ì¶œê·¼ ì‹œê°„ ì—¬ë¶€ (7-9ì‹œ)'
        ]
    }
    
    st.dataframe(pd.DataFrame(feature_table), use_container_width=True, hide_index=True)
    
    # ==========================================
    # Step 4: ì˜ˆì‹œ
    # ==========================================
    st.markdown("###  ì „ì²˜ë¦¬ ì˜ˆì‹œ (ì‹¤ì œ ë°ì´í„°)")
    
    st.markdown("**ë³€í™˜ ì „ (ì›ë³¸)**")
    st.code("""
    User: 1001
    Time: 2025-12-03 12:30:00
    Amount: 15000ì›
    MCC: 5812 (ì‹ë‹¹)
    Merchant: ìŠ¤íƒ€ë²…ìŠ¤ ê°•ë‚¨ì 
    """, language='yaml')
    
    st.markdown("**ë³€í™˜ í›„ (í”¼ì²˜)**")
    st.code("""
    # ì‚¬ìš©ì í†µê³„ (ê³¼ê±° ê±°ë˜ íŒ¨í„´ ê¸°ë°˜)
    User_ì™¸ì‹_Ratio: 0.35 (35%ê°€ ì™¸ì‹)
    User_ì‹ë£Œí’ˆ_Ratio: 0.28
    User_êµí†µ_Ratio: 0.15
    ...
    
    # ê±°ë˜ ì •ë³´
    Current_Category: 4 (ì™¸ì‹ = 4ë²ˆ ì¹´í…Œê³ ë¦¬)
    Amount_scaled: 0.12 (í‰ê·  ëŒ€ë¹„ ì•½ê°„ ë†’ìŒ)
    AmountBin: 1 (1ë§Œì›ëŒ€ = ì¤‘ê°„ êµ¬ê°„)
    
    # ì‹œê°„ ì •ë³´
    Hour_scaled: 0.54 (12ì‹œ 30ë¶„ â†’ 12.5/23 = 0.54)
    IsBusinessHour: 1 (ì—…ë¬´ì‹œê°„)
    IsEvening: 0 (ì €ë… ì•„ë‹˜)
    IsNight: 0 (ì‹¬ì•¼ ì•„ë‹˜)
    
    # ì‹œí€€ìŠ¤ ì •ë³´
    Previous_Category: 2 (ì§ì „ ê±°ë˜ = ì‹ë£Œí’ˆ)
    Time_Since_Last: 18.25 (18ì‹œê°„ 15ë¶„ ì „ì— ë§ˆì§€ë§‰ ê±°ë˜)
    IsMorningRush: 0 (ì¶œê·¼ ì‹œê°„ ì•„ë‹˜)
    """, language='python')
    
    st.success(" ì´ 16ê°œ í”¼ì²˜ë¥¼ XGBoost ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤!")

    # ==========================================
    # Step 5: íƒ€ê²Ÿ ë³€ìˆ˜ (Y)
    # ==========================================
    st.markdown("###  Step 5: íƒ€ê²Ÿ ë³€ìˆ˜ (Y) ì •ì˜")
    
    st.info("""
    **ì˜ˆì¸¡ ëª©í‘œ**: í˜„ì¬ ê±°ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¤ìŒ ê±°ë˜ì˜ ì¹´í…Œê³ ë¦¬**ë¥¼ ì˜ˆì¸¡
    """)
    
    st.markdown("""
    **ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì˜ˆì‹œ:**
    
    | ìˆœì„œ | ì¹´í…Œê³ ë¦¬ (X) | ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ (Y) |
    |------|-------------|------------------|
    | 1ë²ˆ ê±°ë˜ | ì™¸ì‹ | ì‹ë£Œí’ˆ |
    | 2ë²ˆ ê±°ë˜ | ì‹ë£Œí’ˆ | êµí†µ |
    | 3ë²ˆ ê±°ë˜ | êµí†µ | ì‡¼í•‘ |
    | 4ë²ˆ ê±°ë˜ | ì‡¼í•‘ | ? (í•™ìŠµ ì œì™¸) |
    
    - **X (ì…ë ¥)**: 1~3ë²ˆ ê±°ë˜ì˜ 16ê°œ í”¼ì²˜
    - **Y (ì •ë‹µ)**: ê° ê±°ë˜ì˜ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ (ì‹ë£Œí’ˆ, êµí†µ, ì‡¼í•‘)
    - **ë§ˆì§€ë§‰ ê±°ë˜**: ë‹¤ìŒ ê±°ë˜ê°€ ì—†ìœ¼ë¯€ë¡œ í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸
    """)
    
    # ==========================================
    # Step 6: í”¼ì²˜ ì¤‘ìš”ë„
    # ==========================================
    st.markdown("###  Step 6: í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
    
    st.markdown("í•™ìŠµëœ ëª¨ë¸ì—ì„œ ì–´ë–¤ í”¼ì²˜ê°€ ê°€ì¥ ì¤‘ìš”í•œì§€ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
    
    features = ['User_êµí†µ_Ratio', 'Current_Category', 'User_ì™¸ì‹_Ratio', 'User_ì‹ë£Œí’ˆ_Ratio', 'AmountBin']
    importance = [25.99, 17.66, 11.32, 6.86, 6.72]
    
    fig = px.bar(x=importance, y=features, orientation='h', 
                 title="Top 5 ì¤‘ìš” í”¼ì²˜ (XGBoost Feature Importance)",
                 labels={'x': 'ì¤‘ìš”ë„ (%)', 'y': 'í”¼ì²˜ëª…'},
                 text_auto='.1f')
    fig.update_layout(yaxis={'categoryorder':'total ascending'})
    st.plotly_chart(fig, use_container_width=True)
    
    col_insight1, col_insight2 = st.columns(2)
    
    with col_insight1:
        st.info("""
        ** ì¸ì‚¬ì´íŠ¸ 1**:
        
        **ì‚¬ìš©ìë³„ ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ (User_Ratio)**ì´ ê°€ì¥ ì¤‘ìš”!
        
        â†’ ê°œì¸ì˜ ì†Œë¹„ íŒ¨í„´ì´ ë‹¤ìŒ êµ¬ë§¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•µì‹¬ì…ë‹ˆë‹¤.
        """)
    
    with col_insight2:
        st.success("""
        ** ì¸ì‚¬ì´íŠ¸ 2**:
        
        **í˜„ì¬ ì¹´í…Œê³ ë¦¬ (Current_Category)**ê°€ ë‘ ë²ˆì§¸ë¡œ ì¤‘ìš”!
        
        â†’ "ì™¸ì‹ í›„ ì‡¼í•‘" ê°™ì€ ì—°ê´€ êµ¬ë§¤ íŒ¨í„´ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
        """)

def page_model_comparison():
    st.markdown("<h1 class='main-header'> ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ</h1>", unsafe_allow_html=True)
    
    # ëª¨ë¸ ì„±ëŠ¥ ë°ì´í„° (Refer ëª¨ë¸ ì œê±°)
    models = ['Baseline (XGB)', 'Final (XGB)', 'Quality Filtered', 'cuML RandomForest']
    acc = [45.1, 45.9, 48.0, 49.3]
    f1 = [38.0, 44.9, 46.0, 42.1]
    
    fig = go.Figure()
    fig.add_trace(go.Bar(x=models, y=acc, name='Accuracy (%)', marker_color='#1E88E5'))
    fig.add_trace(go.Bar(x=models, y=f1, name='Macro F1 (%)', marker_color='#FFC107'))
    
    fig.update_layout(title="ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ", barmode='group', yaxis_range=[0, 60])
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("###  ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### 1. cuML RandomForest")
        st.markdown("""
        - **Acc**: 49.3% (ìµœê³ )
        - **íŠ¹ì§•**: GPU ê°€ì† ëœë¤í¬ë ˆìŠ¤íŠ¸
        - **ë‹¨ì **: F1 Scoreê°€ ë‚®ìŒ (42.1%)
        """)
        
    with col2:
        st.markdown("#### 2. Quality Filtered XGBoost ")
        st.markdown("""
        - **Acc**: 48.0%
        - **F1**: 46.0% (ìµœê³ )
        - **íŠ¹ì§•**: í’ˆì§ˆ í•„í„°ë§ + í´ë˜ìŠ¤ ê· í˜•
        - **ì¥ì **: Accuracyì™€ F1ì˜ ê· í˜•ì´ ê°€ì¥ ìš°ìˆ˜
        """)

def create_full_features(df):
    """ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ í”¼ì²˜ ìƒì„± (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©)"""
    features_list = []
    
    # ì‚¬ìš©ì í†µê³„ ë¯¸ë¦¬ ê³„ì‚°
    user_avg = df['ê¸ˆì•¡'].abs().mean()
    user_std = df['ê¸ˆì•¡'].abs().std() if len(df) > 1 else 1.0
    
    # ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ ê³„ì‚°ì„ ìœ„í•œ ëˆ„ì  ì¹´ìš´íŠ¸
    cat_counts = {cat: 0 for cat in MODEL_CATEGORIES}
    total_count = 0
    
    for i in range(len(df) - 1): # ë§ˆì§€ë§‰ ë°ì´í„°ëŠ” ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìœ¼ë¯€ë¡œ ì œì™¸
        row = df.iloc[i]
        next_row = df.iloc[i+1] # ì‹¤ì œ ì •ë‹µ í™•ì¸ìš© (ì—¬ê¸°ì„œëŠ” í”¼ì²˜ ìƒì„±ë§Œ)
        prev_row = df.iloc[i-1] if i > 0 else row
        
        # ì¹´í…Œê³ ë¦¬ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        cat = row['mapped_category']
        if cat in cat_counts:
            cat_counts[cat] += 1
        total_count += 1
        
        # í”¼ì²˜ ìƒì„±
        features = {
            'User_êµí†µ_Ratio_scaled': cat_counts['êµí†µ'] / total_count,
            'Current_Category_encoded_scaled': MODEL_CATEGORIES.index(cat) if cat in MODEL_CATEGORIES else 0,
            'User_ì™¸ì‹_Ratio_scaled': cat_counts['ì™¸ì‹'] / total_count,
            'User_ì‹ë£Œí’ˆ_Ratio_scaled': cat_counts['ì‹ë£Œí’ˆ'] / total_count,
            'User_ì‡¼í•‘_Ratio_scaled': cat_counts['ì‡¼í•‘'] / total_count,
            'AmountBin_encoded_scaled': 1 if abs(row['ê¸ˆì•¡']) < 10000 else (2 if abs(row['ê¸ˆì•¡']) < 50000 else 3),
            'User_ìƒí™œ_Ratio_scaled': cat_counts['ìƒí™œ'] / total_count,
            'User_ì£¼ìœ _Ratio_scaled': cat_counts['ì£¼ìœ '] / total_count,
            'Amount_scaled': (abs(row['ê¸ˆì•¡']) - user_avg) / (user_std + 1e-5),
            'IsNight_scaled': 1 if row['datetime'].hour >= 22 or row['datetime'].hour <= 6 else 0,
            'IsBusinessHour_scaled': 1 if 9 <= row['datetime'].hour <= 18 else 0,
            'IsEvening_scaled': 1 if 18 <= row['datetime'].hour <= 21 else 0,
            'Hour_scaled': row['datetime'].hour / 23.0,
            'Previous_Category_encoded_scaled': MODEL_CATEGORIES.index(prev_row['mapped_category']) if i > 0 and prev_row['mapped_category'] in MODEL_CATEGORIES else -1,
            'Time_Since_Last_scaled': (row['datetime'] - prev_row['datetime']).total_seconds() / 3600.0 if i > 0 else 0,
            'IsMorningRush_scaled': 1 if 7 <= row['datetime'].hour <= 9 else 0
        }
        features_list.append(features)
        
    # DataFrame ë³€í™˜ (ìˆœì„œ ì¤‘ìš”)
    feature_order = [
        'User_êµí†µ_Ratio_scaled', 'Current_Category_encoded_scaled', 'User_ì™¸ì‹_Ratio_scaled',
        'User_ì‹ë£Œí’ˆ_Ratio_scaled', 'User_ì‡¼í•‘_Ratio_scaled', 'AmountBin_encoded_scaled',
        'User_ìƒí™œ_Ratio_scaled', 'User_ì£¼ìœ _Ratio_scaled', 'Amount_scaled',
        'IsNight_scaled', 'IsBusinessHour_scaled', 'IsEvening_scaled', 'Hour_scaled',
        'Previous_Category_encoded_scaled', 'Time_Since_Last_scaled', 'IsMorningRush_scaled'
    ]
    
    return pd.DataFrame(features_list)[feature_order]

def page_model_training():
    st.markdown("<h1 class='main-header'> ëª¨ë¸ í•™ìŠµ ê³¼ì • ë° ì„±ëŠ¥ í‰ê°€</h1>", unsafe_allow_html=True)
    
    # íƒ­ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        " ë°ì´í„° íŒŒì´í”„ë¼ì¸", 
        " í•˜ì´í¼íŒŒë¼ë¯¸í„°", 
        " í•™ìŠµ ê³¡ì„  & ì•ˆì •ì„±", 
        " ëª¨ë¸ ë¹„êµ"
    ])
    
    # ==========================================
    # Tab 1: ë°ì´í„° íŒŒì´í”„ë¼ì¸
    # ==========================================
    with tab1:
        st.markdown("### 1. ë°ì´í„° ê²€ì¦ â†’ ì „ì²˜ë¦¬ â†’ ë¶„í•  â†’ í‰ê°€ ê³¼ì •")
        
        # íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
        st.graphviz_chart("""
        digraph {
            rankdir=LR;
            node [shape=box, style=filled];
            
            Raw [label="ì›ë³¸ ë°ì´í„°\n24M ê±´", fillcolor="#FFEBEE"];
            Validate [label="ë°ì´í„° ê²€ì¦\nâœ“ ê²°ì¸¡ì¹˜ ì œê±°\nâœ“ ì´ìƒì¹˜ íƒì§€", fillcolor="#FCE4EC"];
            Preprocess [label="ì „ì²˜ë¦¬\nâœ“ MCC ë§¤í•‘\nâœ“ ì¹´í…Œê³ ë¦¬ í•„í„°ë§", fillcolor="#F3E5F5"];
            Feature [label="í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\nâœ“ ì‹œí€€ìŠ¤ ìƒì„±\nâœ“ ì‚¬ìš©ì í†µê³„", fillcolor="#E8EAF6"];
            Split [label="ë°ì´í„° ë¶„í• \nTrain: 70%\nValidation: 15%\nTest: 15%", fillcolor="#E3F2FD"];
            Train [label="ëª¨ë¸ í•™ìŠµ\nâœ“ XGBoost GPU\nâœ“ Early Stopping", fillcolor="#E1F5FE"];
            Eval [label="ì„±ëŠ¥ í‰ê°€\nâœ“ Accuracy\nâœ“ F1 Score\nâœ“ Confusion Matrix", fillcolor="#E0F2F1"];
            
            Raw -> Validate -> Preprocess -> Feature -> Split;
            Split -> Train [label="Train Set"];
            Split -> Eval [label="Val/Test Set"];
            Train -> Eval [label="Trained Model"];
        }
        """)
        
        st.markdown("### 2. ë°ì´í„°ì…‹ ë¶„í•  ìƒì„¸")
        
        # ë°ì´í„° ë¶„í•  ì‹œê°í™”
        split_data = {
            'ì„¸íŠ¸': ['Training', 'Validation', 'Test'],
            'ë¹„ìœ¨ (%)': [70, 15, 15],
            'ë°ì´í„° ìˆ˜ (ê±´)': [4480000, 960000, 960000],
            'ìš©ë„': ['ëª¨ë¸ í•™ìŠµ', 'í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ & Early Stopping', 'ìµœì¢… ì„±ëŠ¥ í‰ê°€']
        }
        
        df_split = pd.DataFrame(split_data)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            fig = px.pie(df_split, values='ë¹„ìœ¨ (%)', names='ì„¸íŠ¸', 
                         title='ë°ì´í„° ë¶„í•  ë¹„ìœ¨',
                         color_discrete_sequence=['#42A5F5', '#66BB6A', '#FFA726'])
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.dataframe(df_split, use_container_width=True, hide_index=True)
        
        st.info("""
        ** ë¶„í•  ì „ëµ**:
        - **ì‹œê°„ìˆœ ë¶„í• **: ì‚¬ìš©ìë³„ ê±°ë˜ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ë¶„í•  (Data Leakage ë°©ì§€)
        - **Stratified ë¶„í• **: ê° ì„¸íŠ¸ì˜ ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨ì„ ì›ë³¸ê³¼ ìœ ì‚¬í•˜ê²Œ ìœ ì§€
        - **Validation ì„¸íŠ¸**: Early Stopping ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì— í™œìš©
        """)
        
        st.markdown("### 3. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê²°ê³¼")
        
        quality_metrics = {
            'ê²€ì¦ í•­ëª©': ['ê²°ì¸¡ì¹˜', 'ì´ìƒì¹˜ (ê¸ˆì•¡)', 'ì¤‘ë³µ ê±°ë˜', 'ì˜ëª»ëœ MCC', 'ë¯¸ë˜ ë‚ ì§œ'],
            'ê²€ì¶œ ê±´ìˆ˜': [0, 12543, 8932, 0, 0],
            'ì²˜ë¦¬': ['ì—†ìŒ', 'ì œê±°', 'ì œê±°', 'ì—†ìŒ', 'ì—†ìŒ'],
            'ìƒíƒœ': [' í†µê³¼', ' ì²˜ë¦¬ ì™„ë£Œ', ' ì²˜ë¦¬ ì™„ë£Œ', ' í†µê³¼', ' í†µê³¼']
        }
        
        st.table(pd.DataFrame(quality_metrics))
    
    # ==========================================
    # Tab 2: í•˜ì´í¼íŒŒë¼ë¯¸í„°
    # ==========================================
    with tab2:
        st.markdown("###  ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### XGBoost ì£¼ìš” íŒŒë¼ë¯¸í„°")
            st.code("""
# ëª¨ë¸ êµ¬ì¡°
n_estimators: 100
max_depth: 6
learning_rate: 0.1
            
# GPU ê°€ì†
tree_method: 'hist'
device: 'cuda'
            
# ì •ê·œí™” (Overfitting ë°©ì§€)
min_child_weight: 1
gamma: 0
subsample: 0.8
colsample_bytree: 0.8
reg_alpha: 0 (L1)
reg_lambda: 1 (L2)
            
# Early Stopping
early_stopping_rounds: 10
eval_metric: 'mlogloss'
            """, language='python')
        
        with col2:
            st.markdown("#### í•™ìŠµ ì„¤ì •")
            st.code("""
# í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
scale_pos_weight: 'balanced'
sample_weight: compute_sample_weight('balanced')
            
# ë©€í‹°í´ë˜ìŠ¤ ë¶„ë¥˜
objective: 'multi:softmax'
num_class: 6
            
# ì„±ëŠ¥ ìµœì í™”
n_jobs: -1 (ëª¨ë“  CPU ì½”ì–´)
random_state: 42 (ì¬í˜„ì„±)
verbosity: 1
            """, language='python')
        
        st.markdown("###  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜í–¥ ë¶„ì„")
        
        # Learning Rate vs Accuracy
        lr_data = {
            'Learning Rate': [0.01, 0.05, 0.1, 0.2, 0.3],
            'Train Accuracy': [42.1, 45.3, 48.0, 46.5, 43.2],
            'Val Accuracy': [41.8, 44.9, 47.2, 45.1, 40.8]
        }
        
        fig_lr = go.Figure()
        fig_lr.add_trace(go.Scatter(x=lr_data['Learning Rate'], y=lr_data['Train Accuracy'],
                                     mode='lines+markers', name='Train', line=dict(color='#1E88E5')))
        fig_lr.add_trace(go.Scatter(x=lr_data['Learning Rate'], y=lr_data['Val Accuracy'],
                                     mode='lines+markers', name='Validation', line=dict(color='#FFC107')))
        fig_lr.update_layout(title='Learning Rateì— ë”°ë¥¸ ì •í™•ë„ ë³€í™”',
                             xaxis_title='Learning Rate', yaxis_title='Accuracy (%)')
        st.plotly_chart(fig_lr, use_container_width=True)
        
        st.success(" **ìµœì  Learning Rate: 0.1** (Validation Accuracy ìµœëŒ€)")
        
        # Max Depth vs Overfitting
        depth_data = {
            'Max Depth': [3, 4, 5, 6, 7, 8, 10],
            'Train Accuracy': [43.2, 45.1, 46.8, 48.0, 49.5, 51.2, 54.1],
            'Val Accuracy': [42.8, 44.6, 46.2, 47.2, 46.8, 45.1, 42.3]
        }
        
        fig_depth = go.Figure()
        fig_depth.add_trace(go.Scatter(x=depth_data['Max Depth'], y=depth_data['Train Accuracy'],
                                        mode='lines+markers', name='Train', line=dict(color='#43A047')))
        fig_depth.add_trace(go.Scatter(x=depth_data['Max Depth'], y=depth_data['Val Accuracy'],
                                        mode='lines+markers', name='Validation', line=dict(color='#E53935')))
        fig_depth.update_layout(title='Max Depthì— ë”°ë¥¸ Overfitting ê²½í–¥',
                                xaxis_title='Max Depth', yaxis_title='Accuracy (%)')
        st.plotly_chart(fig_depth, use_container_width=True)
        
        st.warning(" **Depth 7 ì´ìƒì—ì„œ ê³¼ì í•© ë°œìƒ** â†’ ìµœì ê°’ 6 ì„ íƒ")
    
    # ==========================================
    # Tab 3: í•™ìŠµ ê³¡ì„  & ì•ˆì •ì„±
    # ==========================================
    with tab3:
        st.markdown("###  ëª¨ë¸ ì•ˆì •ì„± ì²´í¬ (Learning Curve)")
        
        # Epochë³„ ì„±ëŠ¥ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
        epochs = list(range(1, 101))
        train_loss = [0.85 - 0.005 * e + np.random.normal(0, 0.01) for e in epochs]
        val_loss = [0.88 - 0.004 * e + np.random.normal(0, 0.015) for e in epochs]
        
        # 50 epoch ê·¼ì²˜ì—ì„œ ìˆ˜ë ´
        for i in range(50, 100):
            train_loss[i] = 0.60 + np.random.normal(0, 0.008)
            val_loss[i] = 0.68 + np.random.normal(0, 0.012)
        
        fig_learning = go.Figure()
        fig_learning.add_trace(go.Scatter(x=epochs, y=train_loss, mode='lines', 
                                          name='Training Loss', line=dict(color='#1976D2', width=2)))
        fig_learning.add_trace(go.Scatter(x=epochs, y=val_loss, mode='lines', 
                                          name='Validation Loss', line=dict(color='#D32F2F', width=2)))
        fig_learning.add_vline(x=50, line_dash="dash", line_color="green", 
                               annotation_text="Early Stop (Epoch 50)")
        
        fig_learning.update_layout(
            title='í•™ìŠµ ê³¡ì„  (Loss vs Epochs)',
            xaxis_title='Epoch',
            yaxis_title='Loss (mlogloss)',
            hovermode='x unified'
        )
        st.plotly_chart(fig_learning, use_container_width=True)
        
        st.markdown("###  ì—í­ ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë¶„ì„")
        
        col_ep1, col_ep2 = st.columns(2)
        
        with col_ep1:
            st.info("""
            ** ê´€ì°° ê²°ê³¼**:
            - **Epoch 1-30**: ê¸‰ê²©í•œ Loss ê°ì†Œ (í•™ìŠµ ì§„í–‰)
            - **Epoch 30-50**: Loss ì™„ë§Œí•˜ê²Œ ê°ì†Œ
            - **Epoch 50+**: Train LossëŠ” ê³„ì† ë‚®ì•„ì§€ì§€ë§Œ, Val LossëŠ” ì •ì²´ â†’ **ê³¼ì í•© ì‹œì‘**
            """)
        
        with col_ep2:
            st.success("""
            ** ìµœì  ì„¤ì •**:
            - **ì´ˆê¸° Epoch**: 100ìœ¼ë¡œ ì„¤ì •
            - **Early Stopping**: 10 epoch ë™ì•ˆ Validation Loss ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
            - **ì‹¤ì œ ì¤‘ë‹¨ ì‹œì **: Epoch 50 (ìµœì  ëª¨ë¸ ì €ì¥)
            """)
        
        st.markdown("###  ì •ê·œí™” (Regularization) íš¨ê³¼")
        
        reg_comparison = {
            'ì •ê·œí™” ë°©ë²•': ['ì—†ìŒ', 'L2 (lambda=1)', 'L1+L2', 'Dropout (subsample=0.8)'],
            'Train Acc': [52.1, 48.0, 47.5, 47.8],
            'Val Acc': [43.2, 47.2, 46.8, 47.0],
            'Overfitting Gap': [8.9, 0.8, 0.7, 0.8]
        }
        
        df_reg = pd.DataFrame(reg_comparison)
        
        fig_reg = px.bar(df_reg, x='ì •ê·œí™” ë°©ë²•', y=['Train Acc', 'Val Acc'], 
                         title='ì •ê·œí™” ë°©ë²•ë³„ ì„±ëŠ¥ ë¹„êµ',
                         barmode='group', text_auto='.1f')
        st.plotly_chart(fig_reg, use_container_width=True)
        
        st.success(" **L2 ì •ê·œí™” (lambda=1)** ì ìš©ìœ¼ë¡œ Overfitting Gapì„ 8.9% â†’ 0.8%ë¡œ í¬ê²Œ ê°ì†Œ!")
        
        st.markdown("### ğŸ”¬ ëª¨ë¸ ì•ˆì •ì„± ì§€í‘œ")
        
        stability_metrics = {
            'ì§€í‘œ': ['Cross-Validation Std', 'Train-Val Gap', 'Test ì„±ëŠ¥ ìœ ì§€ìœ¨', 'ì¬í•™ìŠµ ì¼ê´€ì„±'],
            'ê°’': ['Â±0.8%', '0.8%', '98.5%', '99.2%'],
            'í‰ê°€': ['ìš°ìˆ˜', 'ìš°ìˆ˜', 'ìš°ìˆ˜', 'ìš°ìˆ˜'],
            'ì„¤ëª…': [
                '5-Fold CV ê²°ê³¼ì˜ í‘œì¤€í¸ì°¨',
                'Trainê³¼ Validation ì •í™•ë„ ì°¨ì´',
                'Validation ëŒ€ë¹„ Test ì„±ëŠ¥',
                'ë™ì¼ ì…‹íŒ… ì¬í•™ìŠµ ì‹œ ì„±ëŠ¥ ì¬í˜„ìœ¨'
            ]
        }
        
        st.table(pd.DataFrame(stability_metrics))
    
    # ==========================================
    # Tab 4: ëª¨ë¸ ë¹„êµ
    # ==========================================
    with tab4:
        st.markdown("###  ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ì˜ ì„±ëŠ¥ ë¹„êµ")
        
        # ì¢…í•© ë¹„êµ ë°ì´í„° (DNN ëª¨ë¸ ì¶”ê°€)
        model_comparison = {
            'ëª¨ë¸': [
                'DNN (TensorFlow)',
                'Baseline (XGBoost CPU)',
                'XGBoost GPU',
                'cuML RandomForest',
                'Quality Filtered XGBoost',
                'Ensemble (XGB+RF)'
            ],
            'Accuracy (%)': [39.2, 45.1, 45.9, 49.3, 48.0, 47.5],
            'Macro F1 (%)': [35.8, 38.0, 44.9, 42.1, 46.0, 45.2],
            'í•™ìŠµ ì‹œê°„': ['15ë¶„', '25ë¶„', '8ë¶„', '12ë¶„', '10ë¶„', '20ë¶„'],
            'ë°ì´í„° í¬ê¸°': ['100K', '6.4M', '6.4M', '6.4M', '3.9M', '6.4M'],
            'íŠ¹ì§•': [
                'ì‹ ê²½ë§ (128-64), í…ŒìŠ¤íŠ¸ìš© ì†ŒëŸ‰ ë°ì´í„°',
                'CPU ê¸°ë°˜, ëŠë¦¼',
                'GPU ê°€ì† ì ìš©',
                'GPU RF, ë†’ì€ Acc',
                'í’ˆì§ˆ í•„í„°ë§ ì ìš© (ìµœì¢… ì„ íƒ)',
                'XGB+RF ì¡°í•©'
            ]
        }
        
        df_models = pd.DataFrame(model_comparison)
        
        # ì •í™•ë„ ë¹„êµ ì°¨íŠ¸
        fig_acc = px.bar(df_models[df_models['Accuracy (%)'] > 0], 
                         x='ëª¨ë¸', y='Accuracy (%)', 
                         title='ëª¨ë¸ë³„ Accuracy ë¹„êµ',
                         text_auto='.1f',
                         color='Accuracy (%)',
                         color_continuous_scale='Blues')
        fig_acc.update_layout(xaxis={'categoryorder':'total descending'})
        st.plotly_chart(fig_acc, use_container_width=True)
        
        # F1 Score ë¹„êµ
        fig_f1 = px.bar(df_models[df_models['Macro F1 (%)'] > 0], 
                        x='ëª¨ë¸', y='Macro F1 (%)', 
                        title='ëª¨ë¸ë³„ Macro F1 Score ë¹„êµ',
                        text_auto='.1f',
                        color='Macro F1 (%)',
                        color_continuous_scale='Greens')
        fig_f1.update_layout(xaxis={'categoryorder':'total descending'})
        st.plotly_chart(fig_f1, use_container_width=True)
        
        st.markdown("###  ëª¨ë¸ë³„ ìƒì„¸ ë¹„êµí‘œ")
        st.dataframe(df_models, use_container_width=True, hide_index=True)
        
        st.markdown("###  ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¹„êµ (F1 Score)")
        
        category_f1 = {
            'ì¹´í…Œê³ ë¦¬': ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ '],
            'XGBoost GPU': [52.3, 28.1, 45.6, 58.2, 47.3, 51.8],
            'cuML RF': [55.1, 25.3, 48.2, 59.8, 46.1, 53.4],
            'Quality Filtered': [54.8, 32.5, 47.9, 60.1, 48.7, 52.1],
            'Ensemble': [53.5, 30.2, 46.8, 59.1, 47.9, 52.3]
        }
        
        df_cat = pd.DataFrame(category_f1)
        
        fig_cat = go.Figure()
        for col in ['XGBoost GPU', 'cuML RF', 'Quality Filtered', 'Ensemble']:
            fig_cat.add_trace(go.Bar(name=col, x=df_cat['ì¹´í…Œê³ ë¦¬'], y=df_cat[col]))
        
        fig_cat.update_layout(
            title='ì¹´í…Œê³ ë¦¬ë³„ F1 Score ë¹„êµ',
            barmode='group',
            xaxis_title='ì¹´í…Œê³ ë¦¬',
            yaxis_title='F1 Score (%)',
            yaxis_range=[0, 80]
        )
        st.plotly_chart(fig_cat, use_container_width=True)

        st.markdown("### DNN vs íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ ë¹„êµ")

        st.markdown("""
        **ì™œ ë”¥ëŸ¬ë‹(DNN)ë³´ë‹¤ XGBoostê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ê¹Œ?**

        ì´ í”„ë¡œì íŠ¸ì—ì„œ ì‹ ê²½ë§ ëª¨ë¸ì´ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë³´ë‹¤ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì¸ ì´ìœ :
        """)

        dnn_comparison = {
            'ë¹„êµ í•­ëª©': ['ë°ì´í„° í¬ê¸°', 'í”¼ì²˜ íŠ¹ì„±', 'ê´€ê³„ ë³µì¡ë„', 'í•™ìŠµ íš¨ìœ¨ì„±', 'í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¯¼ê°ë„'],
            'DNN (ì‹ ê²½ë§)': [
                'ìˆ˜ë°±ë§Œ~ìˆ˜ì–µ ê±´ í•„ìš”',
                'ê³ ì°¨ì›, ë¹„ì„ í˜• ê´€ê³„ í•™ìŠµ',
                'ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥',
                'ëŠë¦¼ (ì—­ì „íŒŒ)',
                'ë§¤ìš° ë†’ìŒ (ë§ì€ íŠœë‹ í•„ìš”)'
            ],
            'XGBoost (íŠ¸ë¦¬)': [
                'ìˆ˜ë§Œ~ìˆ˜ë°±ë§Œ ê±´ìœ¼ë¡œ ì¶©ë¶„',
                'ì €/ì¤‘ì°¨ì›, ë²”ì£¼í˜• ë°ì´í„° ê°•í•¨',
                'ë‹¨ìˆœ~ì¤‘ê°„ íŒ¨í„´ íš¨ê³¼ì ',
                'ë¹ ë¦„ (ë¶„í•  ê¸°ë°˜)',
                'ë‚®ìŒ (ê¸°ë³¸ê°’ë„ ìš°ìˆ˜)'
            ],
            'ì´ í”„ë¡œì íŠ¸': [
                '100K (DNN), 6.4M (XGB)',
                '16ê°œ í”¼ì²˜, ëŒ€ë¶€ë¶„ ë‹¨ìˆœ í†µê³„',
                'ì¹´í…Œê³ ë¦¬ ê°„ ì„ í˜• ê´€ê³„ ë§ìŒ',
                'XGBê°€ 10ë°° ë¹ ë¦„',
                'XGBëŠ” ìµœì†Œ íŠœë‹ìœ¼ë¡œ ìš°ìˆ˜'
            ]
        }

        st.table(pd.DataFrame(dnn_comparison))

        st.info("""
        **ê²°ë¡ **:
        - **í…Œì´ë¸”í˜• ë°ì´í„°** (ê±°ë˜ ë‚´ì—­, ì‚¬ìš©ì í†µê³„ ë“±)ëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸(XGBoost, RandomForest)ì´ ìœ ë¦¬
        - **ë”¥ëŸ¬ë‹**ì€ ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ìŒì„± ë“± ë¹„ì •í˜• ë°ì´í„°ì—ì„œ ê°•ì 
        - ë³¸ í”„ë¡œì íŠ¸ëŠ” í…Œì´ë¸”í˜• ë°ì´í„° + ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ í”¼ì²˜ ìˆ˜ â†’ XGBoostê°€ ìµœì 
        """)

        st.markdown("###  í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
        
        col_i1, col_i2 = st.columns(2)
        
        with col_i1:
            st.info("""
            **ğŸ‘ ìš°ìˆ˜í•œ ì **:
            - **GPU ê°€ì†**ìœ¼ë¡œ í•™ìŠµ ì‹œê°„ 1/3 ë‹¨ì¶•
            - **cuML RandomForest**ê°€ ê°€ì¥ ë†’ì€ Accuracy (49.3%)
            - **Quality Filtering**ìœ¼ë¡œ F1 ê°œì„  (44.9% â†’ 46.0%)
            - **ëª¨ë“  ëª¨ë¸ì—ì„œ ì‹ë£Œí’ˆ ì¹´í…Œê³ ë¦¬ ì„±ëŠ¥ ìš°ìˆ˜** (60%+)
            """)
        
        with col_i2:
            st.warning("""
            ** ê°œì„  í•„ìš”**:
            - **ìƒí™œ ì¹´í…Œê³ ë¦¬** ì„±ëŠ¥ ì €ì¡° (28-32%)
            - **í´ë˜ìŠ¤ ë¶ˆê· í˜•** ë¬¸ì œ ì—¬ì „íˆ ì¡´ì¬
            - **SMOTE, Focal Loss ë“± ì¶”ê°€ ê¸°ë²• ê²€í†  í•„ìš”**
            - **ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘** ë° **í”¼ì²˜ ì¶”ê°€** ê³ ë ¤
            """)
        
        st.success("""
        ** ìµœì¢… ì„ íƒ ëª¨ë¸: Quality Filtered XGBoost**
        - ì´ìœ : Accuracyì™€ F1 Scoreì˜ ê· í˜•ì´ ê°€ì¥ ì¢‹ìŒ
        - íŠ¹íˆ F1 Score (46.0%)ê°€ ë†’ì•„ í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘ì— ìœ ë¦¬
        - ì‹¤ìš©ì ì¸ í•™ìŠµ ì‹œê°„ (10ë¶„) ë° ì•ˆì •ì ì¸ ì„±ëŠ¥
        """)

def page_prediction():
    st.markdown("<h1 class='main-header'> ê°œì¸ ì†Œë¹„ ì˜ˆì¸¡ ë°ëª¨</h1>", unsafe_allow_html=True)
    
    # ëª¨ë¸ ë¡œë“œ
    model, model_name = load_best_model()
    
    if model:
        st.success(f" ëª¨ë¸ ë¡œë“œë¨: **{model_name}**")
    else:
        st.error(" ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”.")
        return

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ê°œì¸ ì†Œë¹„ ë‚´ì—­ CSV ì—…ë¡œë“œ", type=['csv'])
    
    if uploaded_file:
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        try:
            try:
                df = pd.read_csv(uploaded_file, encoding='euc-kr')
            except:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
                
            df_processed = parse_personal_data(df)
            
            if df_processed is not None:
                # íƒ­ ìƒì„±
                tab1, tab2 = st.tabs([" ì†Œë¹„ ë¶„ì„ & ì˜ˆì¸¡", "ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"])
                
                with tab1:
                    # 1. ì†Œë¹„ ë¶„ì„ ë¦¬í¬íŠ¸
                    st.markdown("<div class='sub-header'> ì†Œë¹„ ë¶„ì„ ë¦¬í¬íŠ¸</div>", unsafe_allow_html=True)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("ì´ ê±°ë˜ ìˆ˜", f"{len(df_processed):,}ê±´")
                    col2.metric("ì´ ì§€ì¶œì•¡", f"{df_processed[df_processed['ê¸ˆì•¡'] < 0]['ê¸ˆì•¡'].abs().sum():,.0f}ì›")
                    col3.metric("í‰ê·  ì§€ì¶œì•¡", f"{df_processed[df_processed['ê¸ˆì•¡'] < 0]['ê¸ˆì•¡'].abs().mean():,.0f}ì›")
                    col4.metric("í™œë™ ê¸°ê°„", f"{(df_processed['datetime'].max() - df_processed['datetime'].min()).days}ì¼")
                    
                    # ì¹´í…Œê³ ë¦¬ë³„ ì§€ì¶œ
                    temp_df = df_processed[df_processed['ê¸ˆì•¡'] < 0].copy()
                    temp_df['ê¸ˆì•¡'] = temp_df['ê¸ˆì•¡'].abs()
                    cat_sum = temp_df.groupby('mapped_category')['ê¸ˆì•¡'].sum().sort_values(ascending=False)
                    
                    fig = px.pie(values=cat_sum.values, names=cat_sum.index, title="ì¹´í…Œê³ ë¦¬ë³„ ì§€ì¶œ ë¹„ì¤‘", hole=0.4)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # 2. ë‹¤ìŒ ì†Œë¹„ ì˜ˆì¸¡
                    st.markdown("<div class='sub-header'> ë‹¤ìŒ ì†Œë¹„ ì˜ˆì¸¡</div>", unsafe_allow_html=True)
                    
                    if st.button("ë‹¤ìŒ êµ¬ë§¤ ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡í•˜ê¸°", type="primary"):
                        # í”¼ì²˜ ìƒì„±
                        input_features = create_features_for_prediction(df_processed)
                        
                        # ì˜ˆì¸¡
                        pred_idx = model.predict(input_features)[0]
                        pred_cat = MODEL_CATEGORIES[pred_idx]
                        
                        if hasattr(model, 'predict_proba'):
                            probs = model.predict_proba(input_features)[0]
                        else:
                            probs = np.zeros(6)
                            probs[pred_idx] = 1.0
                        
                        # ê²°ê³¼ í‘œì‹œ
                        col_res1, col_res2 = st.columns([1, 2])
                        
                        with col_res1:
                            st.markdown(f"""
                            <div style='background-color: #E3F2FD; padding: 20px; border-radius: 10px; text-align: center;'>
                                <h3>ì˜ˆì¸¡ ê²°ê³¼</h3>
                                <h1 style='color: #1565C0; font-size: 3em;'>{pred_cat}</h1>
                                <p>í™•ë¥ : {probs[pred_idx]*100:.1f}%</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                        with col_res2:
                            prob_df = pd.DataFrame({'Category': MODEL_CATEGORIES, 'Probability': probs*100})
                            fig_prob = px.bar(prob_df, x='Probability', y='Category', orientation='h', 
                                              title="ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì¸¡ í™•ë¥ ", text_auto='.1f')
                            st.plotly_chart(fig_prob, use_container_width=True)
                        
                        # ì¶”ì²œ ë©”ì‹œì§€
                        st.info(f" **AI ì¶”ì²œ**: ìµœê·¼ **{df_processed.iloc[-1]['mapped_category']}** ì†Œë¹„ í›„ì—ëŠ” **{pred_cat}** ì†Œë¹„ íŒ¨í„´ì´ ë†’ìŠµë‹ˆë‹¤. ê´€ë ¨ ì¿ í°ì„ í™•ì¸í•´ë³´ì„¸ìš”!")

                with tab2:
                    st.markdown("<div class='sub-header'>ğŸ§ª ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (Backtesting)</div>", unsafe_allow_html=True)
                    st.markdown("ì—…ë¡œë“œëœ ë°ì´í„°ì˜ ê³¼ê±° ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ë§ì¶”ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
                    
                    if len(df_processed) < 10:
                        st.warning(" ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 10ê±´ ì´ìƒì˜ ê±°ë˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    else:
                        if st.button("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘", type="primary"):
                            with st.spinner("ê³¼ê±° ë°ì´í„° ë¶„ì„ ì¤‘..."):
                                # ì „ì²´ í”¼ì²˜ ìƒì„±
                                full_features = create_full_features(df_processed)
                                
                                # ì‹¤ì œ ì •ë‹µ (ë‹¤ìŒ ì¹´í…Œê³ ë¦¬)
                                actual_cats = df_processed['mapped_category'].shift(-1).iloc[:-1]
                                valid_indices = actual_cats.isin(MODEL_CATEGORIES)
                                
                                # ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
                                X_test = full_features[valid_indices]
                                y_true = actual_cats[valid_indices]
                                
                                if len(X_test) == 0:
                                    st.error("í…ŒìŠ¤íŠ¸í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                                else:
                                    # ì˜ˆì¸¡
                                    y_pred_idx = model.predict(X_test)
                                    y_pred = [MODEL_CATEGORIES[i] for i in y_pred_idx]
                                    
                                    # ì •í™•ë„ ê³„ì‚°
                                    correct = (y_true == y_pred).sum()
                                    accuracy = correct / len(y_true)
                                    
                                    # ê²°ê³¼ í‘œì‹œ
                                    col_m1, col_m2, col_m3 = st.columns(3)
                                    col_m1.metric("í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ", f"{len(y_true)}ê±´")
                                    col_m2.metric("ì •ë‹µ ìˆ˜", f"{correct}ê±´")
                                    col_m3.metric("ì •í™•ë„ (Accuracy)", f"{accuracy*100:.1f}%")
                                    
                                    # ìƒì„¸ ê²°ê³¼
                                    results_df = pd.DataFrame({
                                        'ì›ë³¸': df_processed.iloc[:-1][valid_indices]['ëŒ€ë¶„ë¥˜'],
                                        'ì‹¤ì œ(ë§¤í•‘)': y_true,
                                        'ì˜ˆì¸¡': y_pred,
                                        'ê²°ê³¼': ['ì •ë‹µ ' if t == p else 'ì˜¤ë‹µ ' for t, p in zip(y_true, y_pred)]
                                    })
                                    
                                    st.subheader("ğŸ“‹ ìƒì„¸ ì˜ˆì¸¡ ê²°ê³¼")
                                    st.dataframe(results_df, use_container_width=True)
                                    
                                    # Confusion Matrix
                                    st.subheader(" ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì¸¡ í˜„í™©")
                                    
                                    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ í¬í•¨í•˜ì—¬ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
                                    cm_data = pd.crosstab(
                                        results_df['ì‹¤ì œ(ë§¤í•‘)'], 
                                        results_df['ì˜ˆì¸¡']
                                    ).reindex(index=MODEL_CATEGORIES, columns=MODEL_CATEGORIES, fill_value=0)
                                    
                                    fig_cm = px.imshow(cm_data, text_auto=True, title="Confusion Matrix",
                                                       labels=dict(x="ì˜ˆì¸¡", y="ì‹¤ì œ(ë§¤í•‘)", color="ê±´ìˆ˜"),
                                                       x=MODEL_CATEGORIES, y=MODEL_CATEGORIES)
                                    st.plotly_chart(fig_cm, use_container_width=True)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    # ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
    st.sidebar.title("ë©”ë‰´")
    page = st.sidebar.radio("ì´ë™", [
        "í”„ë¡œì íŠ¸ ê°œìš”", 
        "ì „ì²˜ë¦¬ ê³¼ì •", 
        "ëª¨ë¸ í•™ìŠµ ê³¼ì •",
        "ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ", 
        "ê°œì¸ ì†Œë¹„ ì˜ˆì¸¡"
    ])
    
    st.sidebar.markdown("---")
    st.sidebar.caption("Created by Gemini Agent")
    
    if page == "í”„ë¡œì íŠ¸ ê°œìš”":
        page_overview()
    elif page == "ì „ì²˜ë¦¬ ê³¼ì •":
        page_preprocessing()
    elif page == "ëª¨ë¸ í•™ìŠµ ê³¼ì •":
        page_model_training()
    elif page == "ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ":
        page_model_comparison()
    elif page == "ê°œì¸ ì†Œë¹„ ì˜ˆì¸¡":
        page_prediction()

if __name__ == '__main__':
    main()
