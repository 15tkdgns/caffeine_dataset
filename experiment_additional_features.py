"""
ì¶”ê°€ í”¼ì²˜ ì‹¤í—˜: Merchant + ì‹œí€€ìŠ¤ íŒ¨í„´
- ì›ë³¸ CSVì—ì„œ Merchant City, State ì •ë³´ í™œìš©
- Rolling statistics (ì‹œí€€ìŠ¤)
- ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1M ìƒ˜í”Œ)
"""

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import LabelEncoder
import time

print("="*80)
print("ğŸš€ ì¶”ê°€ í”¼ì²˜ ì‹¤í—˜: Merchant + ì‹œí€€ìŠ¤")
print("="*80)

# ============================================================
# 1. ì›ë³¸ CSV ë¡œë“œ (Merchant ì •ë³´ í¬í•¨)
# ============================================================
print("\n[1/5] ì›ë³¸ CSV ë¡œë“œ")

# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ
df = pd.read_csv('02_data/00_raw/credit_card_transactions-ibm_v2.csv',
                 usecols=['User', 'Year', 'Month', 'Day', 'Time', 'Amount',
                         'Use Chip', 'Merchant Name', 'Merchant City', 
                         'Merchant State', 'MCC'])

print(f"  ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘
import sys
sys.path.append('00_config/00_mapping')
from category_mapping import get_category_mapping

category_map = get_category_mapping()
df['Category'] = df['MCC'].map(category_map)
df = df[df['Category'].notna()].copy()

print(f"  í•„í„°ë§ í›„: {len(df):,}ê±´")

# ============================================================
# 2. ê¸°ë³¸ ì „ì²˜ë¦¬ + Merchant í”¼ì²˜
# ============================================================
print("\n[2/5] ê¸°ë³¸ ì „ì²˜ë¦¬ + Merchant í”¼ì²˜")

# Amount ì •ì œ
df['Amount'] = df['Amount'].str.replace('$', '').str.replace(',', '').astype(float)

# ì‹œê°„ í”¼ì²˜
df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M').dt.hour
df['DayOfWeek'] = pd.to_datetime(df[['Year', 'Month', 'Day']]).dt.dayofweek

# Merchant í”¼ì²˜
print("  Merchant í”¼ì²˜ ìƒì„±...")

# 1) Merchant Name ì¸ì½”ë”© (í•´ì‹œê°’ì´ì§€ë§Œ íŒ¨í„´ ìˆìŒ)
le_merchant = LabelEncoder()
df['Merchant_ID'] = le_merchant.fit_transform(df['Merchant Name'].astype(str))

# 2) Merchant City/State ì¸ì½”ë”©
le_city = LabelEncoder()
le_state = LabelEncoder()
df['Merchant_City_ID'] = le_city.fit_transform(df['Merchant City'].astype(str))
df['Merchant_State_ID'] = le_state.fit_transform(df['Merchant State'].astype(str))

# 3) Merchant ë¹ˆë„
merchant_freq = df['Merchant Name'].value_counts()
df['Merchant_Frequency'] = df['Merchant Name'].map(merchant_freq)

# 4) City í‰ê·  ê¸ˆì•¡
city_avg = df.groupby('Merchant City')['Amount'].mean()
df['City_Avg_Amount'] = df['Merchant City'].map(city_avg)

# 5) State í‰ê·  ê¸ˆì•¡
state_avg = df.groupby('Merchant State')['Amount'].mean()
df['State_Avg_Amount'] = df['Merchant State'].map(state_avg)

# ============================================================
# 3. ì‹œí€€ìŠ¤ íŒ¨í„´ í”¼ì²˜
# ============================================================
print("\n[3/5] ì‹œí€€ìŠ¤ íŒ¨í„´ í”¼ì²˜")

# ë‚ ì§œ ìƒì„± ë° ì •ë ¬
df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])
df = df.sort_values(['User', 'Date', 'Time']).reset_index(drop=True)

print("  ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„±...")

# 1) Rolling statistics (ìµœê·¼ 3ê°œ ê±°ë˜)
df['Rolling_Amount_Mean_3'] = df.groupby('User')['Amount'].transform(
    lambda x: x.rolling(3, min_periods=1).mean().shift(1)
).fillna(0)

df['Rolling_Amount_Std_3'] = df.groupby('User')['Amount'].transform(
    lambda x: x.rolling(3, min_periods=1).std().shift(1)
).fillna(0)

# 2) ê°™ì€ Merchant ì¬ë°©ë¬¸
df['Same_Merchant_Count'] = df.groupby(['User', 'Merchant Name']).cumcount()

# 3) ê°™ì€ State ì—°ì† ê±°ë˜
df['Same_State_Streak'] = (df.groupby('User')['Merchant State'].shift() == df['Merchant State']).astype(int)

# 4) ì‹œê°„ ê°„ê²©
df['Hours_Since_Last'] = df.groupby('User')['Date'].diff().dt.total_seconds() / 3600
df['Hours_Since_Last'] = df['Hours_Since_Last'].fillna(24)  # ì²« ê±°ë˜ëŠ” 24ì‹œê°„

print(f"  âœ… ì´ {len(df.columns)}ê°œ ì»¬ëŸ¼ ìƒì„±")

# ============================================================
# 4. í™œì„± ì‚¬ìš©ì í•„í„°ë§ + Train/Test ë¶„í• 
# ============================================================
print("\n[4/5] ë°ì´í„° ì¤€ë¹„")

# í™œì„± ì‚¬ìš©ì
tx_per_month = df.groupby(['User', 'Year', 'Month']).size()
active_months = tx_per_month[tx_per_month >= 10].reset_index().groupby('User').size()
active_users = active_months[active_months >= 5].index

df = df[df['User'].isin(active_users)].copy()
print(f"  í™œì„± ì‚¬ìš©ì ë°ì´í„°: {len(df):,}ê±´")

# í”¼ì²˜ ì„ íƒ
feature_columns = [
    'Amount', 'Hour', 'DayOfWeek',
    # Merchant í”¼ì²˜
    'Merchant_ID', 'Merchant_City_ID', 'Merchant_State_ID',
    'Merchant_Frequency', 'City_Avg_Amount', 'State_Avg_Amount',
    # ì‹œí€€ìŠ¤ í”¼ì²˜
    'Rolling_Amount_Mean_3', 'Rolling_Amount_Std_3',
    'Same_Merchant_Count', 'Same_State_Streak', 'Hours_Since_Last'
]

# ê°„ë‹¨í•œ Train/Test ë¶„í•  (ìµœê·¼ 20%)
split_idx = int(len(df) * 0.8)
train_df = df.iloc[:split_idx]
test_df = df.iloc[split_idx:]

# ì‚¬ìš©ìë³„ í†µê³„ ì¶”ê°€
user_stats = train_df.groupby('User')['Amount'].agg(['mean', 'std', 'count'])
train_df['User_AvgAmount'] = train_df['User'].map(user_stats['mean'])
train_df['User_StdAmount'] = train_df['User'].map(user_stats['std']).fillna(0)
test_df['User_AvgAmount'] = test_df['User'].map(user_stats['mean']).fillna(train_df['Amount'].mean())
test_df['User_StdAmount'] = test_df['User'].map(user_stats['std']).fillna(0)

feature_columns.extend(['User_AvgAmount', 'User_StdAmount'])

X_train = train_df[feature_columns].fillna(0).values
y_train = train_df['Category'].astype('category').cat.codes.values
X_test = test_df[feature_columns].fillna(0).values
y_test = test_df['Category'].astype('category').cat.codes.values

print(f"  í•™ìŠµ: {len(X_train):,}ê±´")
print(f"  í…ŒìŠ¤íŠ¸: {len(X_test):,}ê±´")
print(f"  í”¼ì²˜: {len(feature_columns)}ê°œ")

# ìƒ˜í”Œë§ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
sample_size = min(1000000, len(X_train))
np.random.seed(42)
sample_idx = np.random.choice(len(X_train), sample_size, replace=False)
X_train_sample = X_train[sample_idx]
y_train_sample = y_train[sample_idx]

print(f"  ìƒ˜í”Œ: {len(X_train_sample):,}ê±´ (í…ŒìŠ¤íŠ¸ìš©)")

# ============================================================
# 5. LightGBM í•™ìŠµ ë° í‰ê°€
# ============================================================
print("\n[5/5] LightGBM í•™ìŠµ ë° í‰ê°€")

# ê¸°ì¡´ 27ê°œ í”¼ì²˜ vs ìƒˆë¡œìš´ í”¼ì²˜ ë¹„êµ
print("\n  [ë¹„êµ 1] ê¸°ì¡´ í”¼ì²˜ ë¡œë“œ...")
X_train_old = np.load('02_data/02_augmented/X_train_smote.npy')[:sample_size]
y_train_old = np.load('02_data/02_augmented/y_train_smote.npy')[:sample_size]
X_test_old = np.load('02_data/02_augmented/X_test.npy')

# ê¸°ì¡´ í”¼ì²˜ë¡œ í•™ìŠµ
lgb_old = lgb.LGBMClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)

start = time.time()
lgb_old.fit(X_train_old, y_train_old)
time_old = time.time() - start

y_pred_old = lgb_old.predict(X_test_old)
acc_old = accuracy_score(np.load('02_data/02_augmented/y_test.npy'), y_pred_old)

print(f"    âœ… ì™„ë£Œ: {time_old:.2f}ì´ˆ")
print(f"    Accuracy: {acc_old:.4f} ({acc_old*100:.2f}%)")

# ìƒˆë¡œìš´ í”¼ì²˜ë¡œ í•™ìŠµ
print("\n  [ë¹„êµ 2] ìƒˆë¡œìš´ í”¼ì²˜ (Merchant + ì‹œí€€ìŠ¤)...")
lgb_new = lgb.LGBMClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)

start = time.time()
lgb_new.fit(X_train_sample, y_train_sample)
time_new = time.time() - start

y_pred_new = lgb_new.predict(X_test)
acc_new = accuracy_score(y_test, y_pred_new)
f1_new = f1_score(y_test, y_pred_new, average='macro')

print(f"    âœ… ì™„ë£Œ: {time_new:.2f}ì´ˆ")
print(f"    Accuracy: {acc_new:.4f} ({acc_new*100:.2f}%)")
print(f"    Macro F1: {f1_new:.4f}")

# Feature Importance
importances = lgb_new.feature_importances_
top_features = sorted(zip(feature_columns, importances), key=lambda x: -x[1])[:10]

print(f"\n  Top 10 ì¤‘ìš” í”¼ì²˜:")
for rank, (feat, imp) in enumerate(top_features, 1):
    print(f"    {rank:2d}. {feat:25s}: {imp:.0f}")

# ============================================================
# ìµœì¢… ë¹„êµ
# ============================================================
print("\n" + "="*80)
print("ğŸ† ì¶”ê°€ í”¼ì²˜ ì‹¤í—˜ ê²°ê³¼")
print("="*80)

results = [
    ("ê¸°ì¡´ í”¼ì²˜ (27ê°œ)", 27, acc_old),
    ("ìƒˆ í”¼ì²˜ (Merchant+ì‹œí€€ìŠ¤)", len(feature_columns), acc_new),
]

print(f"\n{'ëª¨ë¸':<30} {'í”¼ì²˜ ìˆ˜':>10} {'Accuracy':>12} {'50% ë‹¬ì„±':>12}")
print("-"*70)
for name, n_feat, acc in results:
    status = "âœ…" if acc >= 0.50 else "âŒ"
    print(f"{name:<30} {n_feat:>10} {acc:>12.4f} {status:>12}")
print("-"*70)

improvement = (acc_new - acc_old) * 100
print(f"\nğŸ“Š ê°œì„ ë„:")
print(f"  Accuracy: {improvement:+.2f}%p")

if acc_new >= 0.50:
    print(f"\nğŸ‰ğŸ‰ğŸ‰ 50% ë‹¬ì„± ì„±ê³µ!")
    print(f"   Merchant + ì‹œí€€ìŠ¤ í”¼ì²˜ê°€ íš¨ê³¼ì !")
elif acc_new > acc_old:
    print(f"\nâœ… ì„±ëŠ¥ ê°œì„  í™•ì¸!")
    print(f"   ì¶”ê°€ í”¼ì²˜ê°€ íš¨ê³¼ ìˆìŒ")
else:
    print(f"\nâš ï¸ ê°œì„  íš¨ê³¼ ì œí•œì ")
    print(f"   ë‹¤ë¥¸ ì ‘ê·¼ í•„ìš”")

print("\n" + "="*80)
print("âœ… ì¶”ê°€ í”¼ì²˜ ì‹¤í—˜ ì™„ë£Œ!")
print("="*80)
