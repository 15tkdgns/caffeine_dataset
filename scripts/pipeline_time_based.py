"""
ì‹œê°„ ê¸°ë°˜ Train/Test Split (ë°ì´í„° ìœ ì¶œ ì œê±°)
Train ë°ì´í„°ë¡œë§Œ í”¼ì²˜ ê³„ì‚° â†’ Testì— ì ìš©
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score, accuracy_score
import xgboost as xgb
import json
import os

print("="*80)
print("â° ì‹œê°„ ê¸°ë°˜ Train/Test Split (ë°ì´í„° ìœ ì¶œ ì œê±°)")
print("="*80)

# ============================================================
# 1. ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§
# ============================================================
print("\n[1/6] ë°ì´í„° ë¡œë“œ")

df = pd.read_csv('02_data/00_raw/credit_card_transactions-ibm_v2.csv')
print(f"  ì›ë³¸: {len(df):,}ê±´")

# ë‚ ì§œ ìƒì„±
df['Date'] = pd.to_datetime(
    df['Year'].astype(str) + '-' + 
    df['Month'].astype(str).str.zfill(2) + '-' + 
    df['Day'].astype(str).str.zfill(2)
)

# ìµœê·¼ 10ë…„
max_date = df['Date'].max()
cutoff_date = max_date - timedelta(days=365*10)
df = df[df['Date'] >= cutoff_date].copy()

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘
mcc_to_category = {
    range(5411, 5500): 'ì‹ë£Œí’ˆ', range(5811, 5900): 'ì™¸ì‹',
    range(5200, 5300): 'ì‡¼í•‘', range(5300, 5400): 'ì‡¼í•‘', range(5600, 5700): 'ì‡¼í•‘',
    range(5500, 5600): 'ì£¼ìœ ', range(4000, 4100): 'êµí†µ', range(4100, 4200): 'êµí†µ',
    range(4800, 4900): 'ìƒí™œ', range(6000, 6100): 'ìƒí™œ'
}

def get_category(mcc):
    for mcc_range, cat in mcc_to_category.items():
        if mcc in mcc_range:
            return cat
    return None

df['Category'] = df['MCC'].apply(get_category)
df = df[df['Category'].notna()].copy()

# ë¡œì—´ ê³ ê°
user_stats = df.groupby('User').agg({'Date': ['count', 'min', 'max']}).reset_index()
user_stats.columns = ['User', 'tx_count', 'first_date', 'last_date']
user_stats['monthly_avg'] = user_stats['tx_count'] / ((user_stats['last_date'] - user_stats['first_date']).dt.days / 30 + 1)
loyal_users = user_stats[user_stats['monthly_avg'] >= 10]['User'].values
df = df[df['User'].isin(loyal_users)].copy()

cat_list = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']
cat_to_idx = {cat: i for i, cat in enumerate(cat_list)}
df['Category_idx'] = df['Category'].map(cat_to_idx)

print(f"  í•„í„°ë§ í›„: {len(df):,}ê±´, {len(loyal_users):,}ëª…")

# ============================================================
# 2. ì‹œê°„ ê¸°ë°˜ Train/Test Split (80/20)
# ============================================================
print("\n[2/6] â° ì‹œê°„ ê¸°ë°˜ Train/Test Split")

# 80% ì‹œì  ë‚ ì§œ ê³„ì‚°
df_sorted = df.sort_values('Date')
split_idx = int(len(df_sorted) * 0.8)
split_date = df_sorted.iloc[split_idx]['Date']

train_df = df[df['Date'] < split_date].copy()
test_df = df[df['Date'] >= split_date].copy()

print(f"  Split ë‚ ì§œ: {split_date.date()}")
print(f"  Train: {len(train_df):,}ê±´ ({train_df['Date'].min().date()} ~ {train_df['Date'].max().date()})")
print(f"  Test:  {len(test_df):,}ê±´ ({test_df['Date'].min().date()} ~ {test_df['Date'].max().date()})")

# ============================================================
# 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Trainë§Œ ì‚¬ìš©!)
# ============================================================
print("\n[3/6] í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Train ë°ì´í„°ë§Œ ì‚¬ìš©)")

def add_features(df_input, train_stats=None):
    """í”¼ì²˜ ì¶”ê°€ (train_statsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê³„ì‚°)"""
    df = df_input.copy()
    
    # ê¸ˆì•¡
    df['Amount_clean'] = df['Amount'].replace(r'[\$,]', '', regex=True).astype(float)
    df['Amount_log'] = np.log1p(df['Amount_clean'])
    df['AmountBin'] = pd.cut(df['Amount_clean'], bins=[0, 10, 50, 100, 200, 500, float('inf')], labels=[0, 1, 2, 3, 4, 5]).astype(float).fillna(0)
    
    # ì‹œê°„
    df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.hour.fillna(12)
    df['DayOfWeek'] = df['Date'].dt.dayofweek
    df['DayOfMonth'] = df['Date'].dt.day
    df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)
    df['IsNight'] = ((df['Hour'] >= 22) | (df['Hour'] < 6)).astype(int)
    df['IsBusinessHour'] = ((df['Hour'] >= 9) & (df['Hour'] <= 18)).astype(int)
    
    # ì‚¬ìš©ì í”„ë¡œí•„ (train_stats ì‚¬ìš© ë˜ëŠ” ê³„ì‚°)
    if train_stats is None:
        # Train ë°ì´í„°: ê³„ì‚°
        user_profile = df.groupby('User').agg({'Amount_clean': ['mean', 'std'], 'Category_idx': 'count'}).reset_index()
        user_profile.columns = ['User', 'User_AvgAmount', 'User_StdAmount', 'User_TxCount']
        
        user_cat_counts = df.groupby(['User', 'Category']).size().unstack(fill_value=0)
        user_cat_total = user_cat_counts.sum(axis=1)
        for cat in cat_list:
            if cat in user_cat_counts.columns:
                user_profile[f'User_{cat}_Ratio'] = (user_cat_counts[cat] / user_cat_total).values
            else:
                user_profile[f'User_{cat}_Ratio'] = 0.0
        
        train_stats = user_profile
    
    # ë³‘í•©
    df = df.merge(train_stats, on='User', how='left')
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (Testì— ì—†ëŠ” ì‚¬ìš©ì)
    df['User_AvgAmount'] = df['User_AvgAmount'].fillna(df['Amount_clean'].mean())
    df['User_StdAmount'] = df['User_StdAmount'].fillna(df['Amount_clean'].std())
    df['User_TxCount'] = df['User_TxCount'].fillna(0)
    for cat in cat_list:
        df[f'User_{cat}_Ratio'] = df[f'User_{cat}_Ratio'].fillna(0)
    
    return df, train_stats

# Train í”¼ì²˜ ê³„ì‚°
train_df, train_stats = add_features(train_df, train_stats=None)
print(f"  âœ… Train í”¼ì²˜ ê³„ì‚° ì™„ë£Œ")

# TestëŠ” Train í†µê³„ ì‚¬ìš©!
test_df, _ = add_features(test_df, train_stats=train_stats)
print(f"  âœ… Testì— Train í†µê³„ ì ìš©")

# ============================================================
# 4. ë°ì´í„° ì¤€ë¹„
# ============================================================
print("\n[4/6] ë°ì´í„° ì¤€ë¹„")

feature_cols = [
    'Amount_clean', 'Amount_log', 'AmountBin',
    'Hour', 'DayOfWeek', 'DayOfMonth',
    'IsWeekend', 'IsNight', 'IsBusinessHour',
    'User_AvgAmount', 'User_StdAmount', 'User_TxCount',
    'User_êµí†µ_Ratio', 'User_ìƒí™œ_Ratio', 'User_ì‡¼í•‘_Ratio',
    'User_ì‹ë£Œí’ˆ_Ratio', 'User_ì™¸ì‹_Ratio', 'User_ì£¼ìœ _Ratio'
]

print(f"  í”¼ì²˜: {len(feature_cols)}ê°œ")

# ê²°ì¸¡ê°’ ì²˜ë¦¬
train_df[feature_cols] = train_df[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)
test_df[feature_cols] = test_df[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)

X_train = train_df[feature_cols].values.astype(np.float32)
y_train = train_df['Category_idx'].values.astype(np.int32)
X_test = test_df[feature_cols].values.astype(np.float32)
y_test = test_df['Category_idx'].values.astype(np.int32)

# ìŠ¤ì¼€ì¼ë§ (Trainìœ¼ë¡œë§Œ fit)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)  # Train scaler ì‚¬ìš©

print(f"  í•™ìŠµ: {len(X_train):,}, í…ŒìŠ¤íŠ¸: {len(X_test):,}")

# ============================================================
# 5. ëª¨ë¸ í•™ìŠµ
# ============================================================
print("\n[5/6] XGBoost GPU í•™ìŠµ")

model = xgb.XGBClassifier(
    device='cuda', tree_method='hist',
    n_estimators=300, max_depth=10, learning_rate=0.1,
    subsample=0.8, colsample_bytree=0.8, random_state=42
)

import time
start = time.time()
model.fit(X_train, y_train)
train_time = time.time() - start

print(f"  âœ… í•™ìŠµ ì™„ë£Œ: {train_time:.1f}ì´ˆ")

# ============================================================
# 6. í‰ê°€
# ============================================================
print("\n[6/6] ì„±ëŠ¥ í‰ê°€")

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
macro_f1 = f1_score(y_test, y_pred, average='macro')
category_f1 = f1_score(y_test, y_pred, average=None)

print(f"\n  ğŸ“Š ì „ì²´ ì„±ëŠ¥:")
print(f"    Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"    Macro F1: {macro_f1:.4f} ({macro_f1*100:.2f}%)")

print(f"\n  ì¹´í…Œê³ ë¦¬ë³„ F1:")
for cat, f1 in zip(cat_list, category_f1):
    print(f"    {cat:6s}: {f1:.4f} ({f1*100:.2f}%)")

# ì €ì¥
output_dir = '02_data/06_time_based'
os.makedirs(output_dir, exist_ok=True)

import joblib
joblib.dump(model, f'{output_dir}/xgboost_time_based.joblib')

metadata = {
    'split_method': 'time_based',
    'split_date': str(split_date.date()),
    'train_period': f"{train_df['Date'].min().date()} ~ {train_df['Date'].max().date()}",
    'test_period': f"{test_df['Date'].min().date()} ~ {test_df['Date'].max().date()}",
    'n_features': len(feature_cols),
    'features': feature_cols,
    'accuracy': float(accuracy),
    'macro_f1': float(macro_f1),
    'category_f1': {cat: float(f1) for cat, f1 in zip(cat_list, category_f1)},
    'train_time': train_time,
    'created_at': datetime.now().isoformat()
}

with open(f'{output_dir}/metadata.json', 'w', encoding='utf-8') as f:
    json.dump(metadata, f, indent=2, ensure_ascii=False)

# ============================================================
# ìš”ì•½
# ============================================================
print("\n" + "="*80)
print("âœ… ì‹œê°„ ê¸°ë°˜ Split ì™„ë£Œ!")
print("="*80)

print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
print(f"   ëª©í‘œ: F1 85%")
print(f"   ê²°ê³¼: F1 {macro_f1*100:.2f}%")
if macro_f1 >= 0.85:
    print(f"   âœ… ëª©í‘œ ë‹¬ì„±!")
else:
    print(f"   âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš” ({(0.85 - macro_f1)*100:.2f}%p)")

print(f"\nğŸ“‚ ì €ì¥: {output_dir}")
print("="*80)
