"""
í”¼ì²˜ ì…€ë ‰ì…˜ (Feature Selection)
ëª©í‘œ: 30ê°œ â†’ 15-20ê°œ í•µì‹¬ í”¼ì²˜ë§Œ ì„ íƒ
ë°©ë²•: XGBoost Feature Importance ê¸°ë°˜
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
import json

def load_data(file_path):
    """ë°ì´í„° ë¡œë“œ"""
    print(f"\në°ì´í„° ë¡œë“œ: {file_path}")
    df = pd.read_csv(file_path)
    
    feature_cols = [col for col in df.columns if col.endswith('_scaled')]
    target_col = 'Next_Category_encoded'
    
    X = df[feature_cols].values.astype('float32')
    y = df[target_col].values
    
    print(f"  ì „ì²´ í”¼ì²˜: {len(feature_cols)}ê°œ")
    print(f"  ìƒ˜í”Œ ìˆ˜: {len(X):,}ê°œ")
    
    return X, y, feature_cols


def train_baseline_model(X_train, y_train, X_test, y_test):
    """ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ (í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°ìš©)"""
    print("\në² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ (ì „ì²´ í”¼ì²˜, CPU)...")
    
    model = xgb.XGBClassifier(
        n_estimators=100,  # ë¹ ë¥¸ ê³„ì‚°ìš©
        max_depth=8,
        learning_rate=0.1,
        random_state=42,
        n_jobs=-1  # CPU ë³‘ë ¬
    )
    
    model.fit(X_train, y_train, verbose=False)
    
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    
    print(f"  Accuracy: {acc:.4f}")
    print(f"  Macro F1: {f1:.4f}")
    
    return model


def analyze_feature_importance(model, feature_names, top_k=20):
    """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"""
    print(f"\ní”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (Top {top_k})...")
    
    # ì¤‘ìš”ë„ ì¶”ì¶œ
    importances = model.feature_importances_
    
    # DataFrame ìƒì„±
    importance_df = pd.DataFrame({
        'Feature': [f.replace('_scaled', '') for f in feature_names],
        'Importance': importances
    }).sort_values('Importance', ascending=False)
    
    # Top K
    top_features = importance_df.head(top_k)
    
    print(f"\nìƒìœ„ {top_k}ê°œ í”¼ì²˜:")
    print("="*60)
    for idx, row in top_features.iterrows():
        print(f"{row.name+1:2d}. {row['Feature']:35s} {row['Importance']*100:6.2f}%")
    
    # ëˆ„ì  ì¤‘ìš”ë„
    cumsum = top_features['Importance'].cumsum()
    print(f"\nìƒìœ„ {top_k}ê°œ ëˆ„ì  ì¤‘ìš”ë„: {cumsum.iloc[-1]*100:.2f}%")
    
    return importance_df, top_features


def select_features_by_importance(importance_df, threshold=0.01, min_features=15, max_features=20):
    """
    í”¼ì²˜ ì„ íƒ ì „ëµ
    1. ì¤‘ìš”ë„ threshold ì´ìƒ
    2. ìµœì†Œ min_featuresê°œ
    3. ìµœëŒ€ max_featuresê°œ
    """
    print(f"\ní”¼ì²˜ ì„ íƒ (threshold={threshold*100}%)...")
    
    # threshold ì´ìƒ í”¼ì²˜
    selected = importance_df[importance_df['Importance'] >= threshold]
    
    # ìµœì†Œ/ìµœëŒ€ ì œì•½
    if len(selected) < min_features:
        print(f"  threshold ë¯¸ë‹¬ â†’ ìƒìœ„ {min_features}ê°œ ê°•ì œ ì„ íƒ")
        selected = importance_df.head(min_features)
    elif len(selected) > max_features:
        print(f"  threshold ì´ˆê³¼ â†’ ìƒìœ„ {max_features}ê°œë¡œ ì œí•œ")
        selected = importance_df.head(max_features)
    
    selected_features = selected['Feature'].tolist()
    selected_features_scaled = [f"{f}_scaled" for f in selected_features]
    
    print(f"\nâœ… ì„ íƒëœ í”¼ì²˜: {len(selected_features)}ê°œ")
    print("="*60)
    for idx, feat in enumerate(selected_features, 1):
        imp = selected.loc[selected['Feature'] == feat, 'Importance'].values[0]
        print(f"{idx:2d}. {feat:35s} {imp*100:6.2f}%")
    
    return selected_features_scaled


def evaluate_selected_features(X_train, y_train, X_test, y_test, 
                                 feature_cols, selected_feature_cols):
    """ì„ íƒëœ í”¼ì²˜ë¡œ ì„±ëŠ¥ í‰ê°€"""
    print("\nì„ íƒëœ í”¼ì²˜ë¡œ ì„±ëŠ¥ í‰ê°€ (CPU)...")
    
    # ì¸ë±ìŠ¤ ì¶”ì¶œ
    selected_indices = [feature_cols.index(f) for f in selected_feature_cols]
    
    X_train_selected = X_train[:, selected_indices]
    X_test_selected = X_test[:, selected_indices]
    
    # ëª¨ë¸ í•™ìŠµ
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=10,
        learning_rate=0.1,
        random_state=42,
        n_jobs=-1  # CPU ë³‘ë ¬
    )
    
    model.fit(X_train_selected, y_train, verbose=False)
    
    y_pred = model.predict(X_test_selected)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    
    print(f"  Accuracy: {acc:.4f}")
    print(f"  Macro F1: {f1:.4f}")
    
    return acc, f1


def visualize_importance(importance_df, top_k=20, save_path='feature_importance.png'):
    """í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” (matplotlib í•„ìš”)"""
    print(f"\nâš ï¸ matplotlib ë¯¸ì„¤ì¹˜ë¡œ ì‹œê°í™” ìŠ¤í‚µ")
    return


def main():
    """ë©”ì¸"""
    print("="*70)
    print("í”¼ì²˜ ì…€ë ‰ì…˜ (Feature Selection)")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    data_file = '02_data/01_processed/preprocessed_sequence.csv'
    print(f"âš ï¸ preprocessed_enhanced.csv ì—†ìŒ â†’ preprocessed_sequence.csv ì‚¬ìš©")
    X, y, feature_cols = load_data(data_file)
    
    # ìƒ˜í”Œë§ (GPU ë©”ëª¨ë¦¬ ê³ ë ¤)
    sample_size = min(200000, len(X))  # 100ë§Œ â†’ 20ë§Œ
    print(f"\nâš¡ ë¹ ë¥¸ ë¶„ì„ì„ ìœ„í•´ {sample_size:,}ê°œ ìƒ˜í”Œ ì‚¬ìš© (GPU ë©”ëª¨ë¦¬ ê³ ë ¤)")
    
    indices = np.random.choice(len(X), sample_size, replace=False)
    X_sample = X[indices]
    y_sample = y[indices]
    
    # ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X_sample, y_sample, test_size=0.2, random_state=42, stratify=y_sample
    )
    
    # 1. ë² ì´ìŠ¤ë¼ì¸ (ì „ì²´ í”¼ì²˜)
    print("\n" + "="*70)
    print("1ë‹¨ê³„: ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ì „ì²´ í”¼ì²˜)")
    print("="*70)
    baseline_model = train_baseline_model(X_train, y_train, X_test, y_test)
    
    # 2. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
    print("\n" + "="*70)
    print("2ë‹¨ê³„: í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
    print("="*70)
    importance_df, top_features = analyze_feature_importance(
        baseline_model, feature_cols, top_k=20
    )
    
    # 3. í”¼ì²˜ ì„ íƒ
    print("\n" + "="*70)
    print("3ë‹¨ê³„: í”¼ì²˜ ì„ íƒ")
    print("="*70)
    selected_features = select_features_by_importance(
        importance_df, threshold=0.01, min_features=15, max_features=18
    )
    
    # 4. ì„ íƒëœ í”¼ì²˜ë¡œ ì„±ëŠ¥ í‰ê°€
    print("\n" + "="*70)
    print("4ë‹¨ê³„: ì„ íƒëœ í”¼ì²˜ ì„±ëŠ¥ í‰ê°€")
    print("="*70)
    selected_acc, selected_f1 = evaluate_selected_features(
        X_train, y_train, X_test, y_test, feature_cols, selected_features
    )
    
    # 5. ê²°ê³¼ ìš”ì•½
    print("\n" + "="*70)
    print("ê²°ê³¼ ìš”ì•½")
    print("="*70)
    print(f"\nì „ì²´ í”¼ì²˜ ({len(feature_cols)}ê°œ):")
    print(f"  - ì‚¬ìš©í•œ ë©”ëª¨ë¦¬: 100%")
    print(f"  - í•™ìŠµ ì‹œê°„: ê¸°ì¤€")
    
    print(f"\nì„ íƒëœ í”¼ì²˜ ({len(selected_features)}ê°œ):")
    print(f"  - ì‚¬ìš©í•œ ë©”ëª¨ë¦¬: {len(selected_features)/len(feature_cols)*100:.1f}%")
    print(f"  - í•™ìŠµ ì‹œê°„: ì˜ˆìƒ {len(selected_features)/len(feature_cols)*100:.0f}%")
    print(f"  - Accuracy: {selected_acc:.4f}")
    print(f"  - Macro F1: {selected_f1:.4f}")
    
    # 6. ì„ íƒëœ í”¼ì²˜ ì €ì¥
    selected_features_info = {
        'selected_features': [f.replace('_scaled', '') for f in selected_features],
        'num_features': len(selected_features),
        'total_features': len(feature_cols),
        'reduction_ratio': len(selected_features) / len(feature_cols),
        'performance': {
            'accuracy': float(selected_acc),
            'macro_f1': float(selected_f1)
        }
    }
    
    output_file = '02_data/01_processed/selected_features.json'
    with open(output_file, 'w') as f:
        json.dump(selected_features_info, f, indent=2)
    
    print(f"\nâœ… ì„ íƒëœ í”¼ì²˜ ì •ë³´ ì €ì¥: {output_file}")
    
    # 7. ì‹œê°í™”
    visualize_importance(importance_df, top_k=20, save_path='05_docs/feature_importance.png')
    
    print("\n" + "="*70)
    print("í”¼ì²˜ ì…€ë ‰ì…˜ ì™„ë£Œ!")
    print("="*70)
    print(f"\nğŸ’¡ ê¶Œì¥: {len(selected_features)}ê°œ í”¼ì²˜ ì‚¬ìš©")
    print(f"   ({len(feature_cols) - len(selected_features)}ê°œ ì œê±° â†’ ë©”ëª¨ë¦¬ {(1-len(selected_features)/len(feature_cols))*100:.0f}% ì ˆê°)")


if __name__ == '__main__':
    main()
