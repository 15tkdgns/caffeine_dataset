"""
GPU ê¸°ë°˜ ê·¸ë¦¬ë“œ ì„œì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ìµœì í™” ë²„ì „)
- ë°ì´í„° ëˆ„ì¶œ ì œê±° (MCC í”¼ì²˜ ì œì™¸)
- 1ì‹œê°„ ì´ë‚´ ì™„ë£Œ ëª©í‘œ
- RandomForest GPU ì§ì ‘ êµ¬í˜„
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, f1_score
import joblib
import os
import sys
from datetime import datetime
import json
import itertools

# cuML ì„í¬íŠ¸ ì‹œë„
try:
    from cuml.ensemble import RandomForestClassifier as CumlRFClassifier
    HAS_CUML = True
except ImportError:
    HAS_CUML = False
    print("ê²½ê³ : cuMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. XGBoostë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")


def load_preprocessed_data(file_path, sample_frac=1.0):
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ"""
    print(f"\në°ì´í„° ë¡œë“œ ì¤‘: {file_path}")
    df = pd.read_csv(file_path)
    
    if sample_frac < 1.0:
        print(f"  - ìƒ˜í”Œë§: {sample_frac*100}% ì‚¬ìš©")
        df = df.sample(frac=sample_frac, random_state=42)
    
    print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(df):,}ê±´")
    print(f"  - ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
    
    return df


def prepare_features_target(df):
    """íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬"""
    feature_cols = [col for col in df.columns if col.endswith('_scaled')]
    target_col = 'Category_encoded'
    
    X = df[feature_cols].values.astype('float32')  # float32ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
    y = df[target_col].values
    
    print(f"\níŠ¹ì„± ë° íƒ€ê²Ÿ ì¤€ë¹„:")
    print(f"  - íŠ¹ì„± ìˆ˜: {len(feature_cols)}ê°œ")
    print(f"  - ìƒ˜í”Œ ìˆ˜: {len(X):,}ê°œ")
    print(f"  - í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y))}ê°œ")
    
    return X, y, feature_cols


def xgboost_grid_search_gpu(X_train, y_train, X_test, y_test):
    """XGBoost GPU ê·¸ë¦¬ë“œ ì„œì¹˜ (ì¶•ì†Œ ë²„ì „ - 30ë¶„ ëª©í‘œ)"""
    print("\n" + "="*70)
    print("XGBoost GPU ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘")
    print("="*70)
    
    # ì¶•ì†Œëœ ê·¸ë¦¬ë“œ (27ê°œ ì¡°í•©)
    param_grid = {
        'max_depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.2],
        'n_estimators': [100, 200, 300],
    }
    
    print(f"ê·¸ë¦¬ë“œ ì„œì¹˜ ì„¤ì •:")
    print(f"  - íƒìƒ‰ ì¡°í•© ìˆ˜: {np.prod([len(v) for v in param_grid.values()])}ê°œ")
    print(f"  - CV: ê°„ì†Œí™” (ì‹œê°„ ì ˆì•½)")
    
    best_score = 0
    best_params = None
    best_model = None
    
    start_time = datetime.now()
    
    # ëª¨ë“  ì¡°í•© í…ŒìŠ¤íŠ¸
    combinations = list(itertools.product(*param_grid.values()))
    total = len(combinations)
    
    for idx, (max_depth, lr, n_est) in enumerate(combinations, 1):
        params = {
            'max_depth': max_depth,
            'learning_rate': lr,
            'n_estimators': n_est
        }
        
        model = xgb.XGBClassifier(
            device='cuda',
            tree_method='hist',
            random_state=42,
            eval_metric='mlogloss',
            **params
        )
        
        # í•™ìŠµ
        model.fit(X_train, y_train, verbose=False)
        
        # í‰ê°€
        y_pred = model.predict(X_test)
        score = f1_score(y_test, y_pred, average='weighted')
        
        if score > best_score:
            best_score = score
            best_params = params
            best_model = model
        
        if idx % 5 == 0:
            elapsed = (datetime.now() - start_time).total_seconds()
            print(f"  ì§„í–‰: {idx}/{total} ({idx/total*100:.1f}%) - ê²½ê³¼: {elapsed:.0f}ì´ˆ")
    
    training_time = (datetime.now() - start_time).total_seconds()
    print(f"\ní•™ìŠµ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {training_time:.2f}ì´ˆ ({training_time/60:.2f}ë¶„)")
    
    # ìµœì  íŒŒë¼ë¯¸í„°
    print(f"\nìµœì  íŒŒë¼ë¯¸í„°:")
    for param, value in best_params.items():
        print(f"  - {param}: {value}")
    
    # í…ŒìŠ¤íŠ¸ í‰ê°€
    y_pred = best_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    test_f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"\nìµœì  ì ìˆ˜: {best_score:.4f}")
    print(f"\ní…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
    print(f"  - Accuracy: {test_accuracy:.4f}")
    print(f"  - F1 Score (weighted): {test_f1:.4f}")
    
    return best_model, {
        'model_name': 'xgboost',
        'best_params': best_params,
        'best_score': best_score,
        'test_accuracy': test_accuracy,
        'test_f1': test_f1,
        'training_time': training_time
    }


def randomforest_grid_search_gpu(X_train, y_train, X_test, y_test):
    """cuML RandomForest GPU ê·¸ë¦¬ë“œ ì„œì¹˜ (ì§ì ‘ êµ¬í˜„ - 20ë¶„ ëª©í‘œ)"""
    if not HAS_CUML:
        print("\ncuMLì´ ì—†ì–´ì„œ RandomForest ê·¸ë¦¬ë“œ ì„œì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None, None
    
    print("\n" + "="*70)
    print("cuML RandomForest GPU ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘")
    print("="*70)
    
    # ì¶•ì†Œëœ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (18ê°œ ì¡°í•©)
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 16, 20],
        'max_features': [0.8, 1.0],
    }
    
    print(f"ê·¸ë¦¬ë“œ ì„œì¹˜ ì„¤ì •:")
    print(f"  - íƒìƒ‰ ì¡°í•© ìˆ˜: {np.prod([len(v) for v in param_grid.values()])}ê°œ")
    
    best_score = 0
    best_params = None
    best_model = None
    
    start_time = datetime.now()
    
    # ëª¨ë“  ì¡°í•© í…ŒìŠ¤íŠ¸
    combinations = list(itertools.product(*param_grid.values()))
    total = len(combinations)
    
    for idx, (n_est, max_depth, max_feat) in enumerate(combinations, 1):
        params = {
            'n_estimators': n_est,
            'max_depth': max_depth,
            'max_features': max_feat
        }
        
        try:
            model = CumlRFClassifier(
                random_state=42,
                n_streams=1,
                **params
            )
            
            # í•™ìŠµ
            model.fit(X_train, y_train)
            
            # í‰ê°€
            y_pred = model.predict(X_test)
            score = f1_score(y_test, y_pred, average='weighted')
            
            if score > best_score:
                best_score = score
                best_params = params
                best_model = model
            
            if idx % 5 == 0:
                elapsed = (datetime.now() - start_time).total_seconds()
                print(f"  ì§„í–‰: {idx}/{total} ({idx/total*100:.1f}%) - ê²½ê³¼: {elapsed:.0f}ì´ˆ")
                
        except Exception as e:
            print(f"  ì¡°í•© {idx} ì‹¤íŒ¨: {e}")
            continue
    
    if best_model is None:
        print("\nëª¨ë“  ì¡°í•© ì‹¤íŒ¨")
        return None, None
    
    training_time = (datetime.now() - start_time).total_seconds()
    print(f"\ní•™ìŠµ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {training_time:.2f}ì´ˆ ({training_time/60:.2f}ë¶„)")
    
    # ìµœì  íŒŒë¼ë¯¸í„°
    print(f"\nìµœì  íŒŒë¼ë¯¸í„°:")
    for param, value in best_params.items():
        print(f"  - {param}: {value}")
    
    # í…ŒìŠ¤íŠ¸ í‰ê°€
    y_pred = best_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    test_f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"\nìµœì  ì ìˆ˜: {best_score:.4f}")
    print(f"\ní…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
    print(f"  - Accuracy: {test_accuracy:.4f}")
    print(f"  - F1 Score (weighted): {test_f1:.4f}")
    
    return best_model, {
        'model_name': 'randomforest_cuml',
        'best_params': best_params,
        'best_score': best_score,
        'test_accuracy': test_accuracy,
        'test_f1': test_f1,
        'training_time': training_time
    }


def save_results(model, metadata, model_name, output_dir='03_models/05_gridsearch'):
    """ê·¸ë¦¬ë“œ ì„œì¹˜ ê²°ê³¼ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ìµœì  ëª¨ë¸ ì €ì¥
    model_file = os.path.join(output_dir, f'best_{model_name}_{timestamp}.joblib')
    joblib.dump(model, model_file)
    print(f"\nìµœì  ëª¨ë¸ ì €ì¥: {model_file}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata_file = os.path.join(output_dir, f'metadata_{model_name}_{timestamp}.json')
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)
    print(f"ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_file}")
    
    return model_file, metadata_file


def main():
    """ë©”ì¸ íŒŒì´í”„ë¼ì¸"""
    print("="*70)
    print("GPU ê¸°ë°˜ ê·¸ë¦¬ë“œ ì„œì¹˜ íŒŒì´í”„ë¼ì¸ (ìµœì í™” ë²„ì „)")
    print("="*70)
    
    # ì„¤ì •
    data_file = '02_data/01_processed/preprocessed_full_featured.csv'
    sample_frac = 1.0
    test_size = 0.2
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_preprocessed_data(data_file, sample_frac=sample_frac)
    
    # 2. íŠ¹ì„±/íƒ€ê²Ÿ ì¤€ë¹„
    X, y, feature_cols = prepare_features_target(df)
    
    # 3. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
    print(f"\ní•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (test_size={test_size})...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    print(f"  - í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
    print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´")
    
    # ê²°ê³¼ ì €ì¥ìš©
    all_results = []
    
    # 4. XGBoost ê·¸ë¦¬ë“œ ì„œì¹˜
    try:
        xgb_model, xgb_metadata = xgboost_grid_search_gpu(X_train, y_train, X_test, y_test)
        if xgb_model:
            save_results(xgb_model, xgb_metadata, 'xgboost')
            all_results.append(xgb_metadata)
    except Exception as e:
        print(f"\nXGBoost ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤íŒ¨: {e}")
    
    # 5. RandomForest ê·¸ë¦¬ë“œ ì„œì¹˜
    try:
        rf_model, rf_metadata = randomforest_grid_search_gpu(X_train, y_train, X_test, y_test)
        if rf_model:
            save_results(rf_model, rf_metadata, 'randomforest')
            all_results.append(rf_metadata)
    except Exception as e:
        print(f"\nRandomForest ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤íŒ¨: {e}")
    
    # 6. ìµœì¢… ìš”ì•½
    print("\n" + "="*70)
    print("ê·¸ë¦¬ë“œ ì„œì¹˜ ì™„ë£Œ - ìµœì¢… ìš”ì•½")
    print("="*70)
    
    if all_results:
        summary_df = pd.DataFrame(all_results)
        print("\nëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ:")
        print(summary_df[['model_name', 'test_accuracy', 'test_f1', 'training_time']])
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_idx = summary_df['test_f1'].idxmax()
        best_model = summary_df.loc[best_idx]
        
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['model_name']}")
        print(f"  - Test Accuracy: {best_model['test_accuracy']:.4f}")
        print(f"  - Test F1: {best_model['test_f1']:.4f}")
        print(f"  - í•™ìŠµ ì‹œê°„: {best_model['training_time']:.2f}ì´ˆ ({best_model['training_time']/60:.2f}ë¶„)")
    else:
        print("\nì™„ë£Œëœ ê·¸ë¦¬ë“œ ì„œì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n" + "="*70)
    print("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("="*70)


if __name__ == '__main__':
    main()
