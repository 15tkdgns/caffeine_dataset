"""
Top 3 ëª¨ë¸ ìƒì„¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ìµœê³  ì„±ëŠ¥ ëª¨ë¸ 3ê°œì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„
"""

import pandas as pd
import numpy as np
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report


def load_comparison_results(results_file='03_models/comparison/gpu_models_results.json'):
    """ë¹„êµ ê²°ê³¼ ë¡œë“œ"""
    if not os.path.exists(results_file):
        print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_file}")
        print("ë¨¼ì € ëª¨ë¸ ë¹„êµë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("  python3 01_src/01_training/10_compare_gpu_models.py")
        return None
    
    with open(results_file, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    return results


def select_top3_models(results):
    """Top 3 ëª¨ë¸ ì„ ì • (Accuracy ê¸°ì¤€)"""
    # DataFrameìœ¼ë¡œ ë³€í™˜
    df = pd.DataFrame(results).T
    
    # Accuracy ê¸°ì¤€ ì •ë ¬
    df_sorted = df.sort_values('accuracy', ascending=False)
    
    # Top 3
    top3 = df_sorted.head(3)
    
    print("="*70)
    print("Top 3 ëª¨ë¸ (Accuracy ê¸°ì¤€)")
    print("="*70)
    
    for idx, (model_name, row) in enumerate(top3.iterrows(), 1):
        print(f"\n{idx}. {model_name}")
        print(f"   Accuracy: {row['accuracy']:.4f}")
        print(f"   Macro F1: {row['macro_f1']:.4f}")
        print(f"   Weighted F1: {row['weighted_f1']:.4f}")
        print(f"   Device: {row['device']}")
        print(f"   Framework: {row['framework']}")
        print(f"   í•™ìŠµ ì‹œê°„: {row['train_time']:.2f}ì´ˆ")
        print(f"   ì˜ˆì¸¡ ì‹œê°„: {row['predict_time']:.2f}ì´ˆ")
    
    return top3


def analyze_category_performance(results, top3_models):
    """ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„"""
    print("\n" + "="*70)
    print("ì¹´í…Œê³ ë¦¬ë³„ F1 Score ë¹„êµ")
    print("="*70)
    
    category_names = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']
    
    # ì¹´í…Œê³ ë¦¬ë³„ F1 Score ë°ì´í„° ìˆ˜ì§‘
    category_df = pd.DataFrame()
    
    for model_name in top3_models.index:
        f1_scores = results[model_name]['category_f1']
        category_df[model_name] = f1_scores[:len(category_names)]
    
    category_df.index = category_names
    
    print("\n", category_df.to_string())
    
    # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    print("\n" + "-"*70)
    print("ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸")
    print("-"*70)
    
    for category in category_names:
        best_model = category_df.loc[category].idxmax()
        best_f1 = category_df.loc[category].max()
        print(f"{category:8s}: {best_model:30s} (F1={best_f1:.4f})")
    
    return category_df


def create_detailed_report(top3_models, category_df, output_dir='05_docs'):
    """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, 'TOP3_MODELS_ANALYSIS.md')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# ğŸ† Top 3 ëª¨ë¸ ìƒì„¸ ë¶„ì„\n\n")
        f.write("## ğŸ“Š ì¢…í•© ì„±ëŠ¥ ë¹„êµ\n\n")
        
        # ì¢…í•© ì„±ëŠ¥ í‘œ
        f.write("| ìˆœìœ„ | ëª¨ë¸ | Accuracy | Macro F1 | Weighted F1 | Device | í•™ìŠµ ì‹œê°„ |\n")
        f.write("|------|------|----------|----------|-------------|--------|----------|\n")
        
        for idx, (model_name, row) in enumerate(top3_models.iterrows(), 1):
            f.write(f"| {idx} | **{model_name}** | ")
            f.write(f"{row['accuracy']:.4f} | ")
            f.write(f"{row['macro_f1']:.4f} | ")
            f.write(f"{row['weighted_f1']:.4f} | ")
            f.write(f"{row['device']} | ")
            f.write(f"{row['train_time']:.1f}ì´ˆ |\n")
        
        # ê° ëª¨ë¸ ìƒì„¸ ë¶„ì„
        f.write("\n---\n\n")
        f.write("## ğŸ” ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„\n\n")
        
        for idx, (model_name, row) in enumerate(top3_models.iterrows(), 1):
            f.write(f"### {idx}. {model_name}\n\n")
            
            # ê¸°ë³¸ ì •ë³´
            f.write("**ê¸°ë³¸ ì •ë³´:**\n")
            f.write(f"- Framework: `{row['framework']}`\n")
            f.write(f"- Device: `{row['device']}`\n")
            f.write(f"- í•™ìŠµ ì‹œê°„: {row['train_time']:.2f}ì´ˆ\n")
            f.write(f"- ì˜ˆì¸¡ ì‹œê°„: {row['predict_time']:.2f}ì´ˆ\n\n")
            
            # ì„±ëŠ¥ ì§€í‘œ
            f.write("**ì„±ëŠ¥ ì§€í‘œ:**\n")
            f.write(f"- Accuracy: **{row['accuracy']:.4f}** ({row['accuracy']*100:.2f}%)\n")
            f.write(f"- Macro F1: **{row['macro_f1']:.4f}**\n")
            f.write(f"- Weighted F1: **{row['weighted_f1']:.4f}**\n\n")
            
            # ì¹´í…Œê³ ë¦¬ë³„ F1
            f.write("**ì¹´í…Œê³ ë¦¬ë³„ F1 Score:**\n\n")
            f.write("| ì¹´í…Œê³ ë¦¬ | F1 Score | ë¹„ê³  |\n")
            f.write("|---------|----------|------|\n")
            
            category_names = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']
            for cat_idx, category in enumerate(category_names):
                f1_score = category_df.loc[category, model_name]
                is_best = (f1_score == category_df.loc[category].max())
                marker = " ğŸ†" if is_best else ""
                f.write(f"| {category} | {f1_score:.4f} | {marker} |\n")
            
            # ì¥ë‹¨ì  (ëª¨ë¸ë³„ íŠ¹ì§•)
            f.write("\n**ì¥ì :**\n")
            if 'XGBoost' in model_name:
                f.write("- GPU ê°€ì†ìœ¼ë¡œ ë¹ ë¥¸ í•™ìŠµ ì†ë„\n")
                f.write("- ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ê°•ë ¥í•œ ì„±ëŠ¥\n")
                f.write("- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìš©ì´\n")
            elif 'CatBoost' in model_name:
                f.write("- ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ ìš°ìˆ˜\n")
                f.write("- ê³¼ì í•© ë°©ì§€ ê¸°ëŠ¥ ë‚´ì¥\n")
                f.write("- ë””í´íŠ¸ íŒŒë¼ë¯¸í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥\n")
            elif 'RandomForest' in model_name or 'ExtraTrees' in model_name:
                f.write("- ëœë¤ì„±ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\n")
                f.write("- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (class_weight)\n")
                f.write("- í•´ì„ ê°€ëŠ¥í•œ Feature Importance\n")
            elif 'Neural Network' in model_name:
                f.write("- ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ\n")
                f.write("- GPU ê°€ì†ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬\n")
                f.write("- ìœ ì—°í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„\n")
            
            f.write("\n**ë‹¨ì :**\n")
            if 'XGBoost' in model_name:
                f.write("- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ì¶”ê°€ ì„¤ì • í•„ìš”\n")
                f.write("- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ\n")
            elif 'CatBoost' in model_name:
                f.write("- í•™ìŠµ ì†ë„ê°€ ë‹¤ì†Œ ëŠë¦¼\n")
                f.write("- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë§ìŒ\n")
            elif 'CPU' in model_name:
                f.write("- CPU ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ì†ë„ ëŠë¦¼\n")
                f.write("- ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì œí•œì \n")
            elif 'Neural Network' in model_name:
                f.write("- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë³µì¡\n")
                f.write("- í•´ì„ ê°€ëŠ¥ì„± ë‚®ìŒ\n")
            
            f.write("\n---\n\n")
        
        # ì¶”ì²œ ì‚¬í•­
        f.write("## ğŸ’¡ ì¶”ì²œ ì‚¬í•­\n\n")
        best_model = top3_models.index[0]
        best_acc = top3_models.iloc[0]['accuracy']
        
        f.write(f"### í”„ë¡œë•ì…˜ ë°°í¬ ì¶”ì²œ: **{best_model}**\n\n")
        f.write(f"- **ì´ìœ **: ê°€ì¥ ë†’ì€ Accuracy ({best_acc:.4f})\n")
        f.write(f"- **ì¥ì **: {top3_models.iloc[0]['device']} ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¥¸ ì˜ˆì¸¡\n")
        f.write(f"- **ê³ ë ¤ì‚¬í•­**: í•™ìŠµ ì‹œê°„ {top3_models.iloc[0]['train_time']:.1f}ì´ˆ\n\n")
        
        f.write("### ìƒí™©ë³„ ì¶”ì²œ\n\n")
        f.write("1. **ì†ë„ ìš°ì„ **: í•™ìŠµ ì‹œê°„ì´ ê°€ì¥ ì§§ì€ ëª¨ë¸ ì„ íƒ\n")
        f.write("2. **ì •í™•ë„ ìš°ì„ **: Accuracyê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ (í˜„ì¬ 1ìœ„ ëª¨ë¸)\n")
        f.write("3. **ê· í˜• ì¤‘ì‹œ**: Macro F1ì´ ë†’ì€ ëª¨ë¸ (ì†Œìˆ˜ í´ë˜ìŠ¤ ì„±ëŠ¥ ê³ ë ¤)\n\n")
    
    print(f"\nâœ… ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
    return output_file


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*70)
    print("Top 3 ëª¨ë¸ ìƒì„¸ ë¶„ì„")
    print("="*70)
    
    # ê²°ê³¼ ë¡œë“œ
    print("\n[1/3] ëª¨ë¸ ë¹„êµ ê²°ê³¼ ë¡œë“œ")
    results = load_comparison_results()
    
    if not results:
        return
    
    print(f"ì´ {len(results)}ê°œ ëª¨ë¸ ê²°ê³¼ ë¡œë“œë¨")
    
    # Top 3 ì„ ì •
    print("\n[2/3] Top 3 ëª¨ë¸ ì„ ì •")
    top3_models = select_top3_models(results)
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„
    print("\n[3/3] ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„")
    category_df = analyze_category_performance(results, top3_models)
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
    print("\n[4/4] ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±")
    report_file = create_detailed_report(top3_models, category_df)
    
    print("\n" + "="*70)
    print("ë¶„ì„ ì™„ë£Œ!")
    print("="*70)
    print(f"\nìƒì„¸ ë¦¬í¬íŠ¸: {report_file}")
    print("\në‹¤ìŒ ë‹¨ê³„: ë¦¬í¬íŠ¸ í™•ì¸ í›„ ìµœì  ëª¨ë¸ ì„ íƒ")


if __name__ == '__main__':
    main()
