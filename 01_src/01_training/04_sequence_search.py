"""
ì‹œí€€ìŠ¤ ì˜ˆì¸¡ GPU ê·¸ë¦¬ë“œ ì„œì¹˜
X: í˜„ì¬ ê±°ë˜ ì¹´í…Œê³ ë¦¬ + íŠ¹ì„±
Y: ë‹¤ìŒ ê±°ë˜ ì¹´í…Œê³ ë¦¬
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, f1_score
import joblib
import os
from datetime import datetime
import json
import itertools

try:
    from cuml.ensemble import RandomForestClassifier as CumlRFClassifier
    HAS_CUML = True
except ImportError:
    HAS_CUML = False


def load_sequence_data(file_path, sample_frac=1.0):
    """ì‹œí€€ìŠ¤ ë°ì´í„° ë¡œë“œ"""
    print(f"\në°ì´í„° ë¡œë“œ: {file_path}")
    df = pd.read_csv(file_path)
    
    if sample_frac < 1.0:
        print(f"  ìƒ˜í”Œë§: {sample_frac*100}%")
        df = df.sample(frac=sample_frac, random_state=42)
    
    print(f"  ì´ ì‹œí€€ìŠ¤: {len(df):,}ê°œ")
    return df


def prepare_sequence_data(df):
    """ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„"""
    feature_cols = [col for col in df.columns if col.endswith('_scaled')]
    target_col = 'Next_Category_encoded'
    
    X = df[feature_cols].values.astype('float32')
    y = df[target_col].values
    
    print(f"\níŠ¹ì„±/íƒ€ê²Ÿ ì¤€ë¹„:")
    print(f"  íŠ¹ì„± ìˆ˜: {len(feature_cols)}ê°œ")
    print(f"  ì‹œí€€ìŠ¤ ìˆ˜: {len(X):,}ê°œ")
    print(f"  í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(y))}ê°œ")
    
    # í˜„ì¬ ì¹´í…Œê³ ë¦¬ê°€ íŠ¹ì„±ì— í¬í•¨ëëŠ”ì§€ í™•ì¸
    current_cat_features = [f for f in feature_cols if 'Current_Category' in f]
    print(f"  âœ“ í˜„ì¬ ì¹´í…Œê³ ë¦¬ í”¼ì²˜: {current_cat_features}")
    
    return X, y, feature_cols


def xgboost_sequence_search(X_train, y_train, X_test, y_test):
    """XGBoost ì‹œí€€ìŠ¤ ì˜ˆì¸¡"""
    print("\n" + "="*70)
    print("XGBoost ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ê·¸ë¦¬ë“œ ì„œì¹˜")
    print("="*70)
    
    param_grid = {
        'max_depth': [6, 8, 10],
        'learning_rate': [0.05, 0.1, 0.2],
        'n_estimators': [100, 200, 300],
    }
    
    best_score = 0
    best_params = None
    best_model = None
    
    start_time = datetime.now()
    combinations = list(itertools.product(*param_grid.values()))
    total = len(combinations)
    
    print(f"ì´ {total}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸...")
    
    for idx, (max_depth, lr, n_est) in enumerate(combinations, 1):
        params = {
            'max_depth': max_depth,
            'learning_rate': lr,
            'n_estimators': n_est
        }
        
        model = xgb.XGBClassifier(
            device='cuda',
            tree_method='hist',
            random_state=42,
            eval_metric='mlogloss',
            **params
        )
        
        model.fit(X_train, y_train, verbose=False)
        y_pred = model.predict(X_test)
        score = f1_score(y_test, y_pred, average='weighted')
        
        if score > best_score:
            best_score = score
            best_params = params
            best_model = model
        
        if idx % 5 == 0:
            elapsed = (datetime.now() - start_time).total_seconds()
            print(f"  ì§„í–‰: {idx}/{total} - F1: {score:.4f} - ê²½ê³¼: {elapsed:.0f}ì´ˆ")
    
    training_time = (datetime.now() - start_time).total_seconds()
    
    y_pred = best_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    test_f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"\nâœ… ì™„ë£Œ ({training_time:.0f}ì´ˆ)")
    print(f"ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
    print(f"í…ŒìŠ¤íŠ¸ Accuracy: {test_accuracy:.4f}")
    print(f"í…ŒìŠ¤íŠ¸ F1: {test_f1:.4f}")
    
    return best_model, {
        'model_name': 'xgboost_sequence',
        'best_params': best_params,
        'test_accuracy': test_accuracy,
        'test_f1': test_f1,
        'training_time': training_time
    }


def randomforest_sequence_search(X_train, y_train, X_test, y_test):
    """RandomForest ì‹œí€€ìŠ¤ ì˜ˆì¸¡"""
    if not HAS_CUML:
        return None, None
    
    print("\n" + "="*70)
    print("RandomForest ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ê·¸ë¦¬ë“œ ì„œì¹˜")
    print("="*70)
    
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 16, 20],
        'max_features': [0.8, 1.0],
    }
    
    best_score = 0
    best_params = None
    best_model = None
    
    start_time = datetime.now()
    combinations = list(itertools.product(*param_grid.values()))
    total = len(combinations)
    
    print(f"ì´ {total}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸...")
    
    for idx, (n_est, max_depth, max_feat) in enumerate(combinations, 1):
        params = {
            'n_estimators': n_est,
            'max_depth': max_depth,
            'max_features': max_feat
        }
        
        try:
            model = CumlRFClassifier(random_state=42, n_streams=1, **params)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            score = f1_score(y_test, y_pred, average='weighted')
            
            if score > best_score:
                best_score = score
                best_params = params
                best_model = model
            
            if idx % 3 == 0:
                elapsed = (datetime.now() - start_time).total_seconds()
                print(f"  ì§„í–‰: {idx}/{total} - F1: {score:.4f} - ê²½ê³¼: {elapsed:.0f}ì´ˆ")
        except Exception as e:
            print(f"  ì¡°í•© {idx} ì‹¤íŒ¨: {e}")
    
    if best_model is None:
        return None, None
    
    training_time = (datetime.now() - start_time).total_seconds()
    
    y_pred = best_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    test_f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"\nâœ… ì™„ë£Œ ({training_time:.0f}ì´ˆ)")
    print(f"ìµœì  íŒŒë¼ë¯¸í„°: {best_params}")
    print(f"í…ŒìŠ¤íŠ¸ Accuracy: {test_accuracy:.4f}")
    print(f"í…ŒìŠ¤íŠ¸ F1: {test_f1:.4f}")
    
    return best_model, {
        'model_name': 'randomforest_sequence',
        'best_params': best_params,
        'test_accuracy': test_accuracy,
        'test_f1': test_f1,
        'training_time': training_time
    }


def save_results(model, metadata, output_dir='03_models/06_sequence'):
    """ê²°ê³¼ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_name = metadata['model_name']
    
    model_file = os.path.join(output_dir, f'best_{model_name}_{timestamp}.joblib')
    metadata_file = os.path.join(output_dir, f'metadata_{model_name}_{timestamp}.json')
    
    joblib.dump(model, model_file)
    with open(metadata_file, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"\nëª¨ë¸ ì €ì¥: {model_file}")
    print(f"ë©”íƒ€ ì €ì¥: {metadata_file}")
    
    return model_file, metadata_file


def main():
    """ë©”ì¸"""
    print("="*70)
    print("ì‹œí€€ìŠ¤ ì˜ˆì¸¡ GPU ê·¸ë¦¬ë“œ ì„œì¹˜")
    print("í˜„ì¬ ì¹´í…Œê³ ë¦¬ â†’ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    data_file = '02_data/01_processed/preprocessed_sequence.csv'
    df = load_sequence_data(data_file, sample_frac=1.0)
    
    # ë°ì´í„° ì¤€ë¹„
    X, y, feature_cols = prepare_sequence_data(df)
    
    # ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"\ní•™ìŠµ: {len(X_train):,}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test):,}ê°œ")
    
    all_results = []
    
    # XGBoost
    try:
        xgb_model, xgb_meta = xgboost_sequence_search(X_train, y_train, X_test, y_test)
        if xgb_model:
            save_results(xgb_model, xgb_meta)
            all_results.append(xgb_meta)
    except Exception as e:
        print(f"XGBoost ì‹¤íŒ¨: {e}")
    
    # RandomForest
    try:
        rf_model, rf_meta = randomforest_sequence_search(X_train, y_train, X_test, y_test)
        if rf_model:
            save_results(rf_model, rf_meta)
            all_results.append(rf_meta)
    except Exception as e:
        print(f"RandomForest ì‹¤íŒ¨: {e}")
    
    # ìš”ì•½
    print("\n" + "="*70)
    print("ìµœì¢… ê²°ê³¼")
    print("="*70)
    
    if all_results:
        df_results = pd.DataFrame(all_results)
        print("\nì„±ëŠ¥ ë¹„êµ:")
        print(df_results[['model_name', 'test_accuracy', 'test_f1', 'training_time']])
        
        best_idx = df_results['test_f1'].idxmax()
        best = df_results.loc[best_idx]
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best['model_name']}")
        print(f"  Accuracy: {best['test_accuracy']:.4f}")
        print(f"  F1: {best['test_f1']:.4f}")
        print(f"  ì‹œê°„: {best['training_time']:.0f}ì´ˆ")


if __name__ == '__main__':
    main()
