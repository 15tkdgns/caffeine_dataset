"""
GPU ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
- XGBoost (ì´ë¯¸ ì™„ë£Œ)
- cuML RandomForest (GPU)
- ì•™ìƒë¸” (Voting)
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, f1_score
from sklearn.utils.class_weight import compute_sample_weight
import joblib
import json
import os
from datetime import datetime

try:
    from cuml.ensemble import RandomForestClassifier as CumlRF
    HAS_CUML = True
except ImportError:
    HAS_CUML = False
    print("âš ï¸ cuML ì—†ìŒ, RandomForest ìŠ¤í‚µ")


def load_selected_features():
    """í”¼ì²˜ ë¡œë“œ"""
    feature_file = '02_data/01_processed/selected_features_enhanced.json'
    with open(feature_file, 'r', encoding='utf-8') as f:
        feature_info = json.load(f)
    
    selected_features = [f"{f}_scaled" for f in feature_info['selected_features']]
    return selected_features


def load_data(file_path, selected_features):
    """ë°ì´í„° ë¡œë“œ"""
    print(f"\në°ì´í„° ë¡œë“œ: {file_path}")
    df = pd.read_csv(file_path)
    
    X = df[selected_features].values.astype('float32')
    y = df['Next_Category_encoded'].values.astype('int32')
    
    print(f"  ìƒ˜í”Œ: {len(X):,}ê°œ")
    print(f"  í”¼ì²˜: {len(selected_features)}ê°œ")
    
    return X, y


def train_cuml_rf(X_train, y_train, X_test, y_test):
    """cuML RandomForest (GPU)"""
    if not HAS_CUML:
        return None, None
    
    print("\n" + "="*70)
    print("cuML RandomForest (GPU)")
    print("="*70)
    
    import cupy as cp
    
    # GPUë¡œ ë°ì´í„° ì „ì†¡
    print("ë°ì´í„°ë¥¼ GPUë¡œ ì „ì†¡ ì¤‘...")
    X_train_gpu = cp.array(X_train)
    y_train_gpu = cp.array(y_train)
    X_test_gpu = cp.array(X_test)
    
    # ëª¨ë¸ ìƒì„±
    model = CumlRF(
        n_estimators=200,
        max_depth=15,
        max_features=0.8,
        n_streams=4,  # GPU ë³‘ë ¬ ìŠ¤íŠ¸ë¦¼
        random_state=42
    )
    
    print("\ní•™ìŠµ ì‹œì‘...")
    start_time = datetime.now()
    
    model.fit(X_train_gpu, y_train_gpu)
    
    training_time = (datetime.now() - start_time).total_seconds()
    print(f"í•™ìŠµ ì™„ë£Œ: {training_time:.1f}ì´ˆ")
    
    # ì˜ˆì¸¡
    print("ì˜ˆì¸¡ ì¤‘...")
    y_pred_gpu = model.predict(X_test_gpu)
    y_pred = cp.asnumpy(y_pred_gpu).astype(int)
    
    # CPUë¡œ ë³µì‚¬
    del X_train_gpu, y_train_gpu, X_test_gpu, y_pred_gpu
    
    # í‰ê°€
    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    
    print(f"\nì„±ëŠ¥:")
    print(f"  Accuracy:      {acc:.4f} ({acc*100:.2f}%)")
    print(f"  Macro F1:      {f1_macro:.4f}")
    print(f"  Weighted F1:   {f1_weighted:.4f}")
    
    return model, {
        'accuracy': acc,
        'macro_f1': f1_macro,
        'weighted_f1': f1_weighted,
        'training_time': training_time
    }


def train_voting_ensemble(X_train, y_train, X_test, y_test):
    """ì•™ìƒë¸” (XGBoost + cuML RF)"""
    print("\n" + "="*70)
    print("Voting Ensemble (XGBoost + cuML RF)")
    print("="*70)
    
    # XGBoost
    print("\n[1/2] XGBoost í•™ìŠµ...")
    xgb_model = xgb.XGBClassifier(
        device='cuda',
        tree_method='hist',
        max_depth=10,
        learning_rate=0.1,
        n_estimators=200,
        random_state=42
    )
    xgb_model.fit(X_train, y_train, verbose=False)
    xgb_pred_proba = xgb_model.predict_proba(X_test)
    
    # cuML RF
    if not HAS_CUML:
        print("âš ï¸ cuML ì—†ìŒ, XGBoostë§Œ ì‚¬ìš©")
        return xgb_model, None
    
    print("[2/2] cuML RandomForest í•™ìŠµ...")
    import cupy as cp
    
    X_train_gpu = cp.array(X_train)
    y_train_gpu = cp.array(y_train)
    X_test_gpu = cp.array(X_test)
    
    rf_model = CumlRF(
        n_estimators=150,
        max_depth=12,
        random_state=42
    )
    rf_model.fit(X_train_gpu, y_train_gpu)
    rf_pred_proba_gpu = rf_model.predict_proba(X_test_gpu)
    rf_pred_proba = cp.asnumpy(rf_pred_proba_gpu)
    
    del X_train_gpu, y_train_gpu, X_test_gpu, rf_pred_proba_gpu
    
    # Soft Voting
    print("\nì•™ìƒë¸” ì˜ˆì¸¡ (Soft Voting)...")
    ensemble_proba = (xgb_pred_proba + rf_pred_proba) / 2
    ensemble_pred = np.argmax(ensemble_proba, axis=1)
    
    # í‰ê°€
    acc = accuracy_score(y_test, ensemble_pred)
    f1_macro = f1_score(y_test, ensemble_pred, average='macro')
    f1_weighted = f1_score(y_test, ensemble_pred, average='weighted')
    
    print(f"\nì•™ìƒë¸” ì„±ëŠ¥:")
    print(f"  Accuracy:      {acc:.4f} ({acc*100:.2f}%)")
    print(f"  Macro F1:      {f1_macro:.4f}")
    print(f"  Weighted F1:   {f1_weighted:.4f}")
    
    return {
        'xgb': xgb_model,
        'rf': rf_model
    }, {
        'accuracy': acc,
        'macro_f1': f1_macro,
        'weighted_f1': f1_weighted
    }


def main():
    """ë©”ì¸"""
    print("="*70)
    print("GPU ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    selected_features = load_selected_features()
    data_file = '02_data/01_processed/preprocessed_enhanced.csv'
    X, y = load_data(data_file, selected_features)
    
    # ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"\ní•™ìŠµ: {len(X_train):,}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test):,}ê°œ")
    
    results = {}
    
    # 1. cuML RandomForest
    rf_model, rf_perf = train_cuml_rf(X_train, y_train, X_test, y_test)
    if rf_perf:
        results['RandomForest'] = rf_perf
    
    # 2. Voting Ensemble
    ensemble_models, ensemble_perf = train_voting_ensemble(X_train, y_train, X_test, y_test)
    if ensemble_perf:
        results['Ensemble'] = ensemble_perf
    
    # 3. ì´ì „ XGBoost ê²°ê³¼ ë¡œë“œ
    xgb_result_file = '03_models/08_final/metadata_20251203_120028.json'
    if os.path.exists(xgb_result_file):
        with open(xgb_result_file, 'r') as f:
            xgb_meta = json.load(f)
            results['XGBoost'] = xgb_meta['performance']
    
    # ìµœì¢… ë¹„êµ
    print("\n" + "="*70)
    print("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
    print("="*70)
    print(f"\n{'ëª¨ë¸':<20} {'Accuracy':>10} {'Macro F1':>10} {'Weighted F1':>12}")
    print("-"*70)
    
    for model_name, perf in results.items():
        print(f"{model_name:<20} {perf['accuracy']:>9.4f} {perf['macro_f1']:>10.4f} {perf.get('weighted_f1', 0):>12.4f}")
    
    # Refer ëª¨ë¸
    print("-"*70)
    print(f"{'Refer (ëª©í‘œ)':<20} {0.6309:>9.4f} {0.5486:>10.4f} {'N/A':>12}")
    print("="*70)
    
    # ìµœê³  ëª¨ë¸
    best_model = max(results.items(), key=lambda x: x[1]['macro_f1'])
    print(f"\nğŸ† ìµœê³  ëª¨ë¸: {best_model[0]}")
    print(f"   Macro F1: {best_model[1]['macro_f1']:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    if rf_model:
        output_dir = '03_models/09_ensemble'
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # RandomForest ì €ì¥ (pickleë¡œ)
        rf_file = os.path.join(output_dir, f'cuml_rf_{timestamp}.pkl')
        import pickle
        with open(rf_file, 'wb') as f:
            pickle.dump(rf_model, f)
        print(f"\nâœ… RandomForest ì €ì¥: {rf_file}")
    
    print("\nğŸ¯ ê²°ë¡ :")
    print(f"  - GPU ê°€ì†ìœ¼ë¡œ ë¹ ë¥¸ í•™ìŠµ ì™„ë£Œ")
    print(f"  - ì•™ìƒë¸”ë¡œ ì„±ëŠ¥ ê°œì„  ì‹œë„")
    print(f"  - Refer ëª¨ë¸ ê°­: {(best_model[1]['macro_f1'] - 0.5486)*100:.2f}%p")


if __name__ == '__main__':
    main()
