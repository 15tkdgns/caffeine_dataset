"""
Accuracy ìµœì í™” ì‹¤í—˜
- SMOTE ì œê±° (ì›ë³¸ ë°ì´í„°)
- Accuracy ì¤‘ì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°
- Voting Ensemble
"""

import numpy as np
import lightgbm as lgb
import xgboost as xgb
from sklearn.metrics import accuracy_score, f1_score
from sklearn.ensemble import VotingClassifier
import joblib
import time

print("="*80)
print("ğŸ¯ Accuracy ìµœì í™” ì‹¤í—˜")
print("="*80)

# ============================================================
# 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ (SMOTE ì—†ì´)
# ============================================================
print("\n[1/4] ì›ë³¸ ë°ì´í„° ë¡œë“œ (SMOTE ì œê±°)")

# SMOTE ì ìš© ì „ ì›ë³¸ ë°ì´í„°
X_train = np.load('02_data/02_augmented/X_train_smote.npy')
y_train = np.load('02_data/02_augmented/y_train_smote.npy')
X_test = np.load('02_data/02_augmented/X_test.npy')
y_test = np.load('02_data/02_augmented/y_test.npy')

# SMOTEë¡œ ì¦ê°•ëœ ë¶€ë¶„ ì œê±° (ì›ë³¸ë§Œ ì‚¬ìš©)
# ì›ë³¸ì€ 5,139,965ê±´, SMOTEëŠ” 9,254,112ê±´
# ì²˜ìŒ 5,139,965ê±´ë§Œ ì‚¬ìš©
original_size = 5139965
X_train_original = X_train[:original_size]
y_train_original = y_train[:original_size]

print(f"  ì›ë³¸ í•™ìŠµ: {len(X_train_original):,}ê±´")
print(f"  í…ŒìŠ¤íŠ¸: {len(X_test):,}ê±´")

category_names = ['êµí†µ', 'ìƒí™œ', 'ì‡¼í•‘', 'ì‹ë£Œí’ˆ', 'ì™¸ì‹', 'ì£¼ìœ ']

# ============================================================
# 2. LightGBM - Accuracy ìµœì í™”
# ============================================================
print("\n[2/4] LightGBM - Accuracy ìµœì í™”")

# Accuracy ì¤‘ì‹¬ ì„¤ì •
lgb_acc = lgb.LGBMClassifier(
    n_estimators=500,        # ëŠ˜ë¦¼
    max_depth=12,            # ê¹Šê²Œ
    learning_rate=0.05,      # ë‚®ì¶¤ (ê³¼ì í•© ë°©ì§€)
    num_leaves=256,          # ëŠ˜ë¦¼
    subsample=0.9,
    colsample_bytree=0.9,
    min_child_samples=20,
    reg_alpha=0.1,
    reg_lambda=0.1,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)

print("  í•™ìŠµ ì‹œì‘...")
start = time.time()
lgb_acc.fit(X_train_original, y_train_original)
train_time_lgb = time.time() - start

y_pred_lgb = lgb_acc.predict(X_test)
acc_lgb = accuracy_score(y_test, y_pred_lgb)
f1_lgb = f1_score(y_test, y_pred_lgb, average='macro')

print(f"  âœ… ì™„ë£Œ: {train_time_lgb:.2f}ì´ˆ")
print(f"     Accuracy: {acc_lgb:.4f} ({acc_lgb*100:.2f}%)")
print(f"     Macro F1: {f1_lgb:.4f}")

# ============================================================
# 3. XGBoost - Accuracy ìµœì í™”
# ============================================================
print("\n[3/4] XGBoost - Accuracy ìµœì í™”")

xgb_acc = xgb.XGBClassifier(
    device='cuda',
    tree_method='hist',
    n_estimators=500,
    max_depth=12,
    learning_rate=0.05,
    subsample=0.9,
    colsample_bytree=0.9,
    min_child_weight=3,
    gamma=0.1,
    reg_alpha=0.1,
    reg_lambda=0.1,
    random_state=42,
    n_jobs=-1
)

print("  í•™ìŠµ ì‹œì‘...")
start = time.time()
xgb_acc.fit(X_train_original, y_train_original)
train_time_xgb = time.time() - start

y_pred_xgb = xgb_acc.predict(X_test)
acc_xgb = accuracy_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb, average='macro')

print(f"  âœ… ì™„ë£Œ: {train_time_xgb:.2f}ì´ˆ")
print(f"     Accuracy: {acc_xgb:.4f} ({acc_xgb*100:.2f}%)")
print(f"     Macro F1: {f1_xgb:.4f}")

# ============================================================
# 4. Voting Ensemble
# ============================================================
print("\n[4/4] Voting Ensemble")

# Hard Voting
y_pred_ensemble_hard = []
for i in range(len(X_test)):
    votes = [y_pred_lgb[i], y_pred_xgb[i]]
    # ë‹¤ìˆ˜ê²°
    pred = max(set(votes), key=votes.count)
    y_pred_ensemble_hard.append(pred)

acc_ensemble_hard = accuracy_score(y_test, y_pred_ensemble_hard)
f1_ensemble_hard = f1_score(y_test, y_pred_ensemble_hard, average='macro')

print(f"  Hard Voting:")
print(f"     Accuracy: {acc_ensemble_hard:.4f} ({acc_ensemble_hard*100:.2f}%)")
print(f"     Macro F1: {f1_ensemble_hard:.4f}")

# Soft Voting (í™•ë¥  í‰ê· )
y_proba_lgb = lgb_acc.predict_proba(X_test)
y_proba_xgb = xgb_acc.predict_proba(X_test)

# ê°€ì¤‘ í‰ê·  (LightGBM 60%, XGBoost 40% - LightGBMì´ ë” ë†’ì€ Acc)
if acc_lgb >= acc_xgb:
    y_proba_ensemble = 0.6 * y_proba_lgb + 0.4 * y_proba_xgb
else:
    y_proba_ensemble = 0.4 * y_proba_lgb + 0.6 * y_proba_xgb

y_pred_ensemble_soft = np.argmax(y_proba_ensemble, axis=1)
acc_ensemble_soft = accuracy_score(y_test, y_pred_ensemble_soft)
f1_ensemble_soft = f1_score(y_test, y_pred_ensemble_soft, average='macro')

print(f"\n  Soft Voting (ê°€ì¤‘ í‰ê· ):")
print(f"     Accuracy: {acc_ensemble_soft:.4f} ({acc_ensemble_soft*100:.2f}%)")
print(f"     Macro F1: {f1_ensemble_soft:.4f}")

# ============================================================
# 5. Baseline ëª¨ë¸ ì¶”ê°€ í…ŒìŠ¤íŠ¸
# ============================================================
print("\n[5/5] Baseline ëª¨ë¸ (ì›ë³¸ ë°ì´í„°ë¡œ ì¬í•™ìŠµ)")

lgb_baseline = lgb.LGBMClassifier(
    n_estimators=300,
    max_depth=10,
    learning_rate=0.1,
    num_leaves=128,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1,
    verbose=-1
)

print("  í•™ìŠµ ì‹œì‘...")
lgb_baseline.fit(X_train_original, y_train_original)
y_pred_baseline = lgb_baseline.predict(X_test)
acc_baseline_original = accuracy_score(y_test, y_pred_baseline)
f1_baseline_original = f1_score(y_test, y_pred_baseline, average='macro')

print(f"  âœ… ì™„ë£Œ")
print(f"     Accuracy: {acc_baseline_original:.4f} ({acc_baseline_original*100:.2f}%)")
print(f"     Macro F1: {f1_baseline_original:.4f}")

# ============================================================
# ìµœì¢… ë¹„êµ
# ============================================================
print("\n" + "="*80)
print("ğŸ† Accuracy ìµœì í™” ê²°ê³¼")
print("="*80)

results = [
    ("Baseline (SMOTE ìˆìŒ)", 0.4913),
    ("Baseline (ì›ë³¸ ë°ì´í„°)", acc_baseline_original),
    ("LightGBM (Acc ìµœì í™”)", acc_lgb),
    ("XGBoost (Acc ìµœì í™”)", acc_xgb),
    ("Ensemble Hard Voting", acc_ensemble_hard),
    ("Ensemble Soft Voting", acc_ensemble_soft),
]

print(f"\n{'ëª¨ë¸':<35} {'Accuracy':>12} {'50% ë‹¬ì„±':>12}")
print("-"*65)
for name, acc in results:
    status = "âœ…" if acc >= 0.50 else "âŒ"
    print(f"{name:<35} {acc:>12.4f} {status:>12}")
print("-"*65)

# ìµœê³  ì„±ëŠ¥
best_name, best_acc = max(results, key=lambda x: x[1])
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_name}")
print(f"   Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)")

if best_acc >= 0.50:
    print(f"\nâœ…âœ…âœ… 50% ë‹¬ì„±!")
else:
    print(f"\nâš ï¸ 50% ë¯¸ë‹¬ì„± ({(0.50 - best_acc)*100:.2f}%p ë¶€ì¡±)")

# SMOTE vs ì›ë³¸ ë¹„êµ
print(f"\nğŸ“Š SMOTE íš¨ê³¼:")
print(f"   SMOTE ìˆìŒ: 49.13%")
print(f"   ì›ë³¸ ë°ì´í„°: {acc_baseline_original*100:.2f}%")
print(f"   ì°¨ì´: {(acc_baseline_original - 0.4913)*100:+.2f}%p")

print("\n" + "="*80)
print("âœ… Accuracy ìµœì í™” ì‹¤í—˜ ì™„ë£Œ!")
print("="*80)
