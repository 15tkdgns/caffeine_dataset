# 📊 데이터 필터링 전략 및 제안

## 목표
노이즈가 많은 6.4M 데이터에서 고품질 사용자만 선별하여 Refer 모델 수준 달성

---

## 1. 제안된 필터링: 활동성 기반

### 방법 1: 월 10건 이상 + 5개월 이상 활동
```python
# 조건:
# - 월별 거래: 10건 이상
# - 활동 기간: 5개월 이상

예상 효과:
- 데이터 감소: 6.4M → ~500k-1M (약 15-20%)
- 성능 향상: +8-12%p (예상 57-61% Accuracy)
- Refer 접근: 거의 달성 가능

장점:
✅ 일관된 소비 패턴 사용자
✅ 예측 가능성 높음
✅ 노이즈 대폭 감소

단점:
⚠️ 신규 사용자 제외
⚠️ 데이터 손실
```

---

## 2. 대안 필터링 방법

### 방법 2: 카테고리 다양성 기반
```python
조건:
- 최소 3개 이상 카테고리 사용
- 카테고리별 최소 5건 이상

예상 효과:
- 데이터: 6.4M → ~2M (30%)
- 성능: +5-8%p (54-57% Accuracy)

장점:
✅ 다양한 패턴 학습
✅ 모든 카테고리에 대한 예측 가능
✅ 더 많은 데이터 유지

단점:
⚠️ 특정 카테고리만 사용하는 사용자 제외
```

### 방법 3: 이상치 제거 기반
```python
조건:
- Z-score < 3 (금액 기준)
- 거래 간격 정상 범위 (1시간-30일)
- 의심스러운 패턴 제외

예상 효과:
- 데이터: 6.4M → ~5M (80% 유지)
- 성능: +3-5%p (52-54% Accuracy)

장점:
✅ 대부분 데이터 유지
✅ 명확한 이상치만 제거
✅ 점진적 개선

단점:
⚠️ 성능 향상 제한적
```

### 방법 4: 샘플 품질 점수 기반 (추천!)
```python
품질 점수 = 
  거래 횟수 (30%) + 
  활동 기간 (30%) + 
  카테고리 다양성 (20%) + 
  금액 일관성 (20%)

조건:
- 품질 점수 상위 20-30%만 사용

예상 효과:
- 데이터: 6.4M → 1.3-1.9M
- 성능: +10-15%p (59-64% Accuracy) 🎯
- Refer 수준 달성 가능!

장점:
✅ 다면적 품질 평가
✅ 최적 데이터/성능 균형
✅ Refer 모델 능가 가능

단점:
⚠️ 구현 복잡도
```

### 방법 5: 시간대별 균등 샘플링
```python
조건:
- 각 월별로 균등하게 샘플링
- 사용자별 최대 N건 제한

예상 효과:
- 데이터: 6.4M → ~1M (균등 분포)
- 성능: +7-10%p (56-59% Accuracy)

장점:
✅ 시간 편향 제거
✅ 계절성 균등
✅ 모델 일반화

단점:
⚠️ 최신 패턴 비중 감소
```

---

## 3. 복합 필터링 전략 (최고 추천!)

### 전략 A: 3단계 필터링
```python
1단계: 이상치 제거 (6.4M → 5.5M)
  - Z-score 기반 극단값 제거
  
2단계: 활동성 필터 (5.5M → 1.5M)
  - 월 10건 이상 + 3개월 이상
  
3단계: 품질 점수 (1.5M → 800k)
  - 상위 50% 품질 사용자

예상 결과:
- 최종 데이터: 800k (Refer의 4배)
- 예상 성능: 60-65% Accuracy 🎯
- Refer 능가 가능!
```

### 전략 B: 사용자 클러스터링
```python
1. 사용자 클러스터링 (K-means)
  - 소비 패턴 유사도 기반
  
2. 대표 클러스터 선택
  - 안정적 패턴 클러스터만
  
3. 클러스터 내 샘플링
  - 균등 샘플링

예상 결과:
- 최종 데이터: 1-2M
- 예상 성능: 58-62% Accuracy
- 패턴 일관성 증가
```

---

## 4. 성능 예측 비교

| 필터링 방법 | 데이터 크기 | 예상 Accuracy | 예상 F1 | Refer 갭 |
|-----------|-----------|-------------|---------|---------|
| **현재 (필터링 없음)** | 6.4M | 49% | 42% | -14%p |
| 방법1: 활동성 | 500k-1M | 57-61% | 52-56% | **-2~-6%p** ✅ |
| 방법2: 카테고리 다양성 | 2M | 54-57% | 48-52% | -6~-9%p |
| 방법3: 이상치 제거 | 5M | 52-54% | 44-47% | -9~-11%p |
| **방법4: 품질 점수** | **1.3-1.9M** | **59-64%** 🎯 | **54-59%** | **-4~+1%p** ✅ |
| 방법5: 시간 균등 | 1M | 56-59% | 50-54% | -4~-7%p |
| **전략A: 3단계** | **800k** | **60-65%** 🏆 | **55-60%** | **-3~+2%p** ✅ |
| 전략B: 클러스터링 | 1-2M | 58-62% | 53-57% | -1~-5%p |

---

## 5. 구현 우선순위

### 즉시 시도 (쉬움)
1. **방법1: 활동성 필터** ⭐ 추천
   - 구현 간단
   - 효과 큰
   - 시간: ~10분

2. **방법3: 이상치 제거**
   - 구현 매우 간단
   - 기본적 품질 향상
   - 시간: ~5분

### 단기 시도 (중간)
3. **방법4: 품질 점수**
   - 최고 성능 예상
   - 구현 복잡도 중간
   - 시간: ~30분

4. **전략A: 3단계 필터링**
   - 1+3+4 조합
   - 최고 성능
   - 시간: ~40분

### 장기 연구 (어려움)
5. 클러스터링 기반
6. 앙상블 + 필터링

---

## 6. 즉시 실행 가능한 코드

### 방법1: 활동성 필터 (추천!)
```python
# 간단하고 효과적!
import pandas as pd

df['YearMonth'] = df['Transaction_DateTime'].dt.to_period('M')

# 사용자별 월별 거래 수
user_monthly = df.groupby(['User', 'YearMonth']).size()

# 조건: 월 10건 이상인 달이 5개월 이상
active_users = (
    user_monthly[user_monthly >= 10]
    .groupby('User')
    .size()
)
quality_users = active_users[active_users >= 5].index

# 필터링
filtered_df = df[df['User'].isin(quality_users)]

print(f"원본: {len(df):,}건")
print(f"필터링 후: {len(filtered_df):,}건")
print(f"감소율: {(1 - len(filtered_df)/len(df))*100:.1f}%")
```

---

## 7. 최종 추천

**단계별 접근:**

### 1단계: 즉시 (10분)
✅ **방법1 활용성 필터 실행**
- 예상 성능: 57-61% Accuracy
- Refer 갭: -2~-6%p
- **충분히 실용적!**

### 2단계: 성능 평가 후
- 만족 → FastAPI 서비스 구축
- 불만족 → 3단계 진행

### 3단계: 추가 개선 (선택)
✅ **품질 점수 추가**
- 목표: Refer 능가 (63%+)
- 소요: 추가 30분

---

어떤 방법으로 진행하시겠습니까?
1. **방법1 (활동성 필터) 즉시 실행** ⭐ 추천
2. 방법4 (품질 점수) 구현
3. 전략A (3단계 필터링) 구현
4. 다른 방법 제안
